{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a514df6",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2589e20",
   "metadata": {},
   "source": [
    "### Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d14845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c92feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(filename, label):\n",
    "    img_read = tf.io.read_file(filename)\n",
    "    img_decode = tf.image.decode_jpeg(img_read, channels=3)\n",
    "    img_resize = tf.image.resize(img_decode, [224,224])\n",
    "    return img_resize, label\n",
    "\n",
    "def create_dataset(filenames, labels) :\n",
    "    BATCH_SIZE = 16\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(16)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac6ea471",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "labels = []\n",
    "with open('./casia/label/label.txt', 'r') as f :\n",
    "    lines = f.readlines()\n",
    "    for line in lines :\n",
    "        line = line.strip()\n",
    "        names.append(line.split()[0])\n",
    "        labels.append([int(i) for i in line.split()[1:]])\n",
    "    \n",
    "image_path = './casia/img'    \n",
    "image_names = [os.path.join(image_path, name) for name in names ]\n",
    "\n",
    "dataset = create_dataset(image_names, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185a3d1",
   "metadata": {},
   "source": [
    "### Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6ed9307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 14, 14, 64)        73792     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 204,358\n",
      "Trainable params: 204,358\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential, layers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Input(shape=(224,224,3)))\n",
    "model.add(layers.Conv2D(32,3,padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64,3,padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64,3,padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(128,3,padding='same', activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64,3,padding='same', activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816dceb2",
   "metadata": {},
   "source": [
    "### define metrics and callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e68527c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='AUC')\n",
    "]\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=5),\n",
    "    tf.keras.callbacks.ModelCheckpoint('./check/cp.ckpt',\n",
    "                                        save_weights_only=True,\n",
    "                                      save_freq='epoch'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        factor=0.1, patience=5,\n",
    "                                        min_lr=1e-13)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af32b1a",
   "metadata": {},
   "source": [
    "### model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b24d2091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "             metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df37371",
   "metadata": {},
   "source": [
    "### model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecfd8ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 397s 634ms/step - loss: 0.4389 - accuracy: 0.8066 - precision: 0.6447 - recall: 0.4599 - AUC: 0.8283\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 482s 771ms/step - loss: 0.3757 - accuracy: 0.8364 - precision: 0.7133 - recall: 0.5495 - AUC: 0.8661\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 463s 740ms/step - loss: 0.3575 - accuracy: 0.8460 - precision: 0.7302 - recall: 0.5840 - AUC: 0.8795\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset,\n",
    "                    batch_size=16,\n",
    "                    epochs=3, \n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54d75dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 262, 262, 3)  0           input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 128, 128, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 128, 128, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 128, 128, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 130, 130, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 64, 64, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 64, 64, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 64, 64, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 64, 64, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 64, 64, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 64, 64, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 64, 64, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 64, 64, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 64, 64, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 64, 64, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 64, 64, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 64, 64, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 64, 64, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 64, 64, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 64, 64, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 32, 32, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 32, 32, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 32, 32, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 32, 32, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 32, 32, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 32, 32, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 32, 32, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 32, 32, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 32, 32, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 32, 32, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 32, 32, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 32, 32, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 32, 32, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 32, 32, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 32, 32, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 32, 32, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 32, 32, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 23,534,592\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet50 = tf.keras.applications.resnet.ResNet50(input_shape=(256,256,3),\n",
    "                                                 weights='imagenet',\n",
    "                                                 include_top=False)\n",
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66facf6a",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d22e6",
   "metadata": {},
   "source": [
    "### dataload - non augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6612bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(filename, label) :\n",
    "    img = tf.io.read_file(filename)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [256,256])\n",
    "    return img, label\n",
    "\n",
    "def create_dataset(filenames, labels) :\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.batch(16)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c1203c",
   "metadata": {},
   "source": [
    "### dataload - augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51edcdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [00:15<00:00, 645.99it/s]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "names = []\n",
    "labels = []\n",
    "with open('./casia/label/label.txt', 'r') as f :\n",
    "    lines = f.readlines()\n",
    "    for line in lines :\n",
    "        line = line.strip()\n",
    "        names.append(line.split()[0])\n",
    "        labels.append([int(i) for i in line.split()[1:]])\n",
    "\n",
    "image_path = './casia/img'\n",
    "image_list = [os.path.join(image_path,name) for name in names]\n",
    "\n",
    "def create_img_dataset(image_list) :\n",
    "    imgs = []\n",
    "    for image in tqdm(image_list) :\n",
    "        img = cv2.imread(image)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, dsize=(256,256))\n",
    "        imgs.append(img)\n",
    "        \n",
    "    return np.array(imgs)\n",
    "\n",
    "image_dataset = create_img_dataset(image_list)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45143838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image dataset : (10000, 256, 256, 3)\n",
      "label dataset : (10000, 6)\n"
     ]
    }
   ],
   "source": [
    "print('image dataset :',image_dataset.shape)\n",
    "print('label dataset :',labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b23b33e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc27cd",
   "metadata": {},
   "source": [
    "### Model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c43061f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 297,414\n",
      "Trainable params: 297,414\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential, layers, activations\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(64, 3, padding='same', input_shape=(256,256,3)))\n",
    "model.add(layers.LeakyReLU(alpha=0.01))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(128, 3, padding='same'))\n",
    "model.add(layers.LeakyReLU(alpha=0.01))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(128, 3, padding='same'))\n",
    "model.add(layers.LeakyReLU(alpha=0.01))\n",
    "model.add(layers.MaxPool2D())\n",
    "\n",
    "model.add(layers.Conv2D(64, 3, padding='same'))\n",
    "model.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "model.add(layers.Dense(6, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602eb396",
   "metadata": {},
   "source": [
    "### define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b4f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics =[\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='AUC')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ef1a24",
   "metadata": {},
   "source": [
    "### define callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ca6d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint('./ckpt_test/cp.ckpt',\n",
    "                                      save_weights_only=True,\n",
    "                                      save_freq='epoch'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        patience=3,\n",
    "                                        factor=0.01,\n",
    "                                        min_lr=1e-13)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf7598a",
   "metadata": {},
   "source": [
    "### model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5edd61b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2ae4417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch : 0\n",
      "\n",
      "\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 0 Acc : [0.8125] Loss : [0.4360867738723755] Precision : [0.7058823704719543] Recall: [0.47999998927116394] AUC : [0.828169047832489]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 1 Acc : [0.8541666269302368] Loss : [0.3832630515098572] Precision : [0.7777777910232544] Recall: [0.5833333134651184] AUC : [0.8871527910232544]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 2 Acc : [0.8125] Loss : [0.40103262662887573] Precision : [0.6315789222717285] Recall: [0.52173912525177] AUC : [0.8442525863647461]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 3 Acc : [0.75] Loss : [0.6080987453460693] Precision : [0.75] Recall: [0.375] AUC : [0.736572265625]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 4 Acc : [0.7916666269302368] Loss : [0.4862979054450989] Precision : [0.761904776096344] Recall: [0.5161290168762207] AUC : [0.826054573059082]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 5 Acc : [0.8229166865348816] Loss : [0.3861325979232788] Precision : [0.6363636255264282] Recall: [0.6086956262588501] AUC : [0.8975580930709839]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 6 Acc : [0.8229166865348816] Loss : [0.47778934240341187] Precision : [0.6666666865348816] Recall: [0.692307710647583] AUC : [0.8068681359291077]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 7 Acc : [0.7395833134651184] Loss : [0.5482112169265747] Precision : [0.40740740299224854] Recall: [0.550000011920929] AUC : [0.6868420839309692]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 8 Acc : [0.8125] Loss : [0.3956754803657532] Precision : [0.5555555820465088] Recall: [0.5] AUC : [0.839802622795105]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 9 Acc : [0.8125] Loss : [0.40636104345321655] Precision : [0.5625] Recall: [0.44999998807907104] AUC : [0.8450658321380615]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 10 Acc : [0.7604166269302368] Loss : [0.40606674551963806] Precision : [0.4375] Recall: [0.3333333432674408] AUC : [0.8415873050689697]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 11 Acc : [0.8020833730697632] Loss : [0.39852169156074524] Precision : [0.5625] Recall: [0.4285714328289032] AUC : [0.8403174877166748]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 12 Acc : [0.8125] Loss : [0.48531484603881836] Precision : [0.75] Recall: [0.4615384638309479] AUC : [0.7920329570770264]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 13 Acc : [0.7291666865348816] Loss : [0.5705008506774902] Precision : [0.5] Recall: [0.3076923191547394] AUC : [0.7211538553237915]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 14 Acc : [0.7916666269302368] Loss : [0.4404715895652771] Precision : [0.5625] Recall: [0.40909090638160706] AUC : [0.8043611645698547]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 15 Acc : [0.7395833730697632] Loss : [0.5606744289398193] Precision : [0.5] Recall: [0.3199999928474426] AUC : [0.7230985760688782]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 16 Acc : [0.75] Loss : [0.4390203356742859] Precision : [0.4375] Recall: [0.3181818127632141] AUC : [0.7902334928512573]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 17 Acc : [0.7916666865348816] Loss : [0.3923741281032562] Precision : [0.6666666865348816] Recall: [0.260869562625885] AUC : [0.8612269163131714]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 18 Acc : [0.7604166269302368] Loss : [0.39356422424316406] Precision : [0.0] Recall: [0.0] AUC : [0.8285714387893677]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 19 Acc : [0.71875] Loss : [0.4804016649723053] Precision : [0.0] Recall: [0.0] AUC : [0.7933440208435059]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 20 Acc : [0.7291666865348816] Loss : [0.38002097606658936] Precision : [0.3333333432674408] Recall: [0.1304347813129425] AUC : [0.8397855758666992]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 21 Acc : [0.78125] Loss : [0.44304513931274414] Precision : [0.529411792755127] Recall: [0.40909090638160706] AUC : [0.802211344242096]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 22 Acc : [0.7083333730697632] Loss : [0.42159682512283325] Precision : [0.4333333373069763] Recall: [0.5416666865348816] AUC : [0.7717013359069824]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 23 Acc : [0.7604166865348816] Loss : [0.452842652797699] Precision : [0.5] Recall: [0.6521739363670349] AUC : [0.8016676902770996]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 24 Acc : [0.78125] Loss : [0.3560028076171875] Precision : [0.4285714328289032] Recall: [0.5] AUC : [0.863603949546814]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 25 Acc : [0.8333333134651184] Loss : [0.43927645683288574] Precision : [0.8235294222831726] Recall: [0.5185185074806213] AUC : [0.8454106450080872]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 26 Acc : [0.8020833134651184] Loss : [0.447273313999176] Precision : [0.625] Recall: [0.43478259444236755] AUC : [0.7992852926254272]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 27 Acc : [0.7604166865348816] Loss : [0.4074065685272217] Precision : [0.5625] Recall: [0.36000001430511475] AUC : [0.8453521728515625]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 28 Acc : [0.7708333730697632] Loss : [0.46645087003707886] Precision : [0.625] Recall: [0.38461539149284363] AUC : [0.8065934181213379]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 29 Acc : [0.8125] Loss : [0.363879919052124] Precision : [0.5625] Recall: [0.44999998807907104] AUC : [0.8851974010467529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 30 Acc : [0.8020833730697632] Loss : [0.40864792466163635] Precision : [0.625] Recall: [0.43478259444236755] AUC : [0.8293627500534058]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 31 Acc : [0.8229166865348816] Loss : [0.40232133865356445] Precision : [0.75] Recall: [0.47999998927116394] AUC : [0.8526760339736938]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 32 Acc : [0.84375] Loss : [0.42153897881507874] Precision : [0.6875] Recall: [0.523809552192688] AUC : [0.800000011920929]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 33 Acc : [0.8229166269302368] Loss : [0.37172114849090576] Precision : [0.75] Recall: [0.47999998927116394] AUC : [0.8754929304122925]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 34 Acc : [0.8020833134651184] Loss : [0.39698103070259094] Precision : [0.625] Recall: [0.43478259444236755] AUC : [0.8576533794403076]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 35 Acc : [0.8333333730697632] Loss : [0.35514307022094727] Precision : [0.6875] Recall: [0.5] AUC : [0.8839066624641418]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 36 Acc : [0.8333333134651184] Loss : [0.3878437280654907] Precision : [0.7647058963775635] Recall: [0.5199999809265137] AUC : [0.8707042336463928]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 37 Acc : [0.7604166269302368] Loss : [0.464851975440979] Precision : [0.5] Recall: [0.3913043439388275] AUC : [0.7882668972015381]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 38 Acc : [0.75] Loss : [0.47861403226852417] Precision : [0.4444444477558136] Recall: [0.3636363744735718] AUC : [0.7515356540679932]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 39 Acc : [0.84375] Loss : [0.3609299063682556] Precision : [0.6666666865348816] Recall: [0.5714285969734192] AUC : [0.8679364919662476]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 40 Acc : [0.7395833730697632] Loss : [0.46449875831604004] Precision : [0.5] Recall: [0.36000001430511475] AUC : [0.7771830558776855]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 41 Acc : [0.78125] Loss : [0.41016846895217896] Precision : [0.4375] Recall: [0.3684210479259491] AUC : [0.7676007747650146]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 42 Acc : [0.7604166269302368] Loss : [0.42965757846832275] Precision : [0.5] Recall: [0.3478260934352875] AUC : [0.7876712083816528]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 43 Acc : [0.8229166865348816] Loss : [0.33779507875442505] Precision : [0.5882353186607361] Recall: [0.5] AUC : [0.8950657844543457]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 44 Acc : [0.7708333730697632] Loss : [0.400175541639328] Precision : [0.529411792755127] Recall: [0.3913043439388275] AUC : [0.8513996005058289]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 45 Acc : [0.75] Loss : [0.537149965763092] Precision : [0.6666666865348816] Recall: [0.2222222238779068] AUC : [0.7595276236534119]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 46 Acc : [0.7708333134651184] Loss : [0.48809635639190674] Precision : [0.8333333134651184] Recall: [0.19230769574642181] AUC : [0.800000011920929]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 47 Acc : [0.78125] Loss : [0.42137712240219116] Precision : [1.0] Recall: [0.08695652335882187] AUC : [0.8347229957580566]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 48 Acc : [0.7395833134651184] Loss : [0.4873512387275696] Precision : [0.3333333432674408] Recall: [0.08695652335882187] AUC : [0.7635496854782104]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 49 Acc : [0.7708333730697632] Loss : [0.4039902985095978] Precision : [0.5] Recall: [0.3181818127632141] AUC : [0.8249385356903076]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 50 Acc : [0.7604166269302368] Loss : [0.41871291399002075] Precision : [0.5] Recall: [0.30434781312942505] AUC : [0.8147707581520081]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 51 Acc : [0.8125] Loss : [0.36565274000167847] Precision : [0.5] Recall: [0.5] AUC : [0.8721508979797363]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 52 Acc : [0.84375] Loss : [0.4042307734489441] Precision : [0.7222222089767456] Recall: [0.5652173757553101] AUC : [0.8597379922866821]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 53 Acc : [0.8333333730697632] Loss : [0.38802570104599] Precision : [0.6315789222717285] Recall: [0.5714285969734192] AUC : [0.8647619485855103]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 54 Acc : [0.8020833134651184] Loss : [0.43895071744918823] Precision : [0.6000000238418579] Recall: [0.625] AUC : [0.8284143209457397]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 55 Acc : [0.8020833730697632] Loss : [0.4848862886428833] Precision : [0.7222222089767456] Recall: [0.48148149251937866] AUC : [0.7922705411911011]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 56 Acc : [0.78125] Loss : [0.3960140645503998] Precision : [0.5] Recall: [0.4285714328289032] AUC : [0.8276190757751465]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 57 Acc : [0.8125] Loss : [0.3373330533504486] Precision : [0.550000011920929] Recall: [0.550000011920929] AUC : [0.8769736886024475]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 58 Acc : [0.84375] Loss : [0.4162018299102783] Precision : [0.8235294222831726] Recall: [0.5384615659713745] AUC : [0.8582417964935303]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 59 Acc : [0.75] Loss : [0.47256678342819214] Precision : [0.5789473652839661] Recall: [0.40740740299224854] AUC : [0.8070316910743713]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 60 Acc : [0.7916666865348816] Loss : [0.4062547981739044] Precision : [0.6499999761581421] Recall: [0.5] AUC : [0.8686813116073608]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 61 Acc : [0.7083333730697632] Loss : [0.5813919305801392] Precision : [0.37931033968925476] Recall: [0.523809552192688] AUC : [0.7841269969940186]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 62 Acc : [0.7708333134651184] Loss : [0.49788206815719604] Precision : [0.5625] Recall: [0.375] AUC : [0.7728587985038757]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 63 Acc : [0.8020833730697632] Loss : [0.3856293857097626] Precision : [0.5625] Recall: [0.4285714328289032] AUC : [0.8431746363639832]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 64 Acc : [0.8020833730697632] Loss : [0.5006020069122314] Precision : [0.7777777910232544] Recall: [0.2916666567325592] AUC : [0.8122106790542603]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 65 Acc : [0.7708333134651184] Loss : [0.5126521587371826] Precision : [0.8333333134651184] Recall: [0.19230769574642181] AUC : [0.8134615421295166]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 66 Acc : [0.7916666269302368] Loss : [0.3716682195663452] Precision : [0.6000000238418579] Recall: [0.1428571492433548] AUC : [0.8574603199958801]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 67 Acc : [0.6979166865348816] Loss : [0.6547635793685913] Precision : [0.6666666865348816] Recall: [0.1875] AUC : [0.726318359375]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 68 Acc : [0.7604166269302368] Loss : [0.47320497035980225] Precision : [0.6000000238418579] Recall: [0.23999999463558197] AUC : [0.7909859418869019]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 69 Acc : [0.8229166269302368] Loss : [0.4108622968196869] Precision : [0.7272727489471436] Recall: [0.3636363744735718] AUC : [0.8310810923576355]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 70 Acc : [0.78125] Loss : [0.4668957591056824] Precision : [0.6153846383094788] Recall: [0.3333333432674408] AUC : [0.8194444179534912]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 71 Acc : [0.6979166269302368] Loss : [0.49422603845596313] Precision : [0.3636363744735718] Recall: [0.3478260934352875] AUC : [0.7418106198310852]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 72 Acc : [0.78125] Loss : [0.4409443736076355] Precision : [0.5] Recall: [0.8571428656578064] AUC : [0.8238095045089722]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 73 Acc : [0.7708333730697632] Loss : [0.4359377920627594] Precision : [0.4864864945411682] Recall: [0.8571428656578064] AUC : [0.8336508274078369]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 74 Acc : [0.7291666865348816] Loss : [0.42286109924316406] Precision : [0.4000000059604645] Recall: [0.7368420958518982] AUC : [0.8280929923057556]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 75 Acc : [0.7708333134651184] Loss : [0.3733028471469879] Precision : [0.46875] Recall: [0.75] AUC : [0.88289475440979]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 76 Acc : [0.8229166269302368] Loss : [0.33441823720932007] Precision : [0.5161290168762207] Recall: [0.8888888955116272] AUC : [0.9241453409194946]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 77 Acc : [0.7291666269302368] Loss : [0.4530993700027466] Precision : [0.5] Recall: [0.6153846383094788] AUC : [0.8087911605834961]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 78 Acc : [0.75] Loss : [0.48799997568130493] Precision : [0.46666666865348816] Recall: [0.6363636255264282] AUC : [0.7724201083183289]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 79 Acc : [0.8020833134651184] Loss : [0.3200705647468567] Precision : [0.5] Recall: [0.8421052694320679] AUC : [0.8622692823410034]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 80 Acc : [0.6979166269302368] Loss : [0.7653648853302002] Precision : [0.5517241358757019] Recall: [0.5] AUC : [0.724609375]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 81 Acc : [0.8229166269302368] Loss : [0.6106199622154236] Precision : [0.800000011920929] Recall: [0.5517241358757019] AUC : [0.7678847312927246]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 82 Acc : [0.7604166865348816] Loss : [0.623673677444458] Precision : [0.7272727489471436] Recall: [0.2857142984867096] AUC : [0.7599790096282959]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 83 Acc : [0.75] Loss : [0.41224515438079834] Precision : [0.3333333432674408] Recall: [0.09090909361839294] AUC : [0.7902334332466125]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 84 Acc : [0.75] Loss : [0.4639936685562134] Precision : [0.5] Recall: [0.125] AUC : [0.7867476940155029]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 85 Acc : [0.8229166269302368] Loss : [0.4047052562236786] Precision : [0.7777777910232544] Recall: [0.3181818127632141] AUC : [0.8737714886665344]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 86 Acc : [0.7708333730697632] Loss : [0.4335433840751648] Precision : [0.5] Recall: [0.22727273404598236] AUC : [0.7957616448402405]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 87 Acc : [0.8333333134651184] Loss : [0.3984488844871521] Precision : [0.7272727489471436] Recall: [0.380952388048172] AUC : [0.8920634984970093]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 88 Acc : [0.8333333134651184] Loss : [0.3936968445777893] Precision : [0.6428571343421936] Recall: [0.44999998807907104] AUC : [0.8766447305679321]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 89 Acc : [0.7916666269302368] Loss : [0.43514561653137207] Precision : [0.5333333611488342] Recall: [0.380952388048172] AUC : [0.7961905002593994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 90 Acc : [0.7083333730697632] Loss : [0.4776347875595093] Precision : [0.375] Recall: [0.25] AUC : [0.7734375]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 91 Acc : [0.7395833730697632] Loss : [0.44451624155044556] Precision : [0.4117647111415863] Recall: [0.3181818127632141] AUC : [0.7991400957107544]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 92 Acc : [0.8020833730697632] Loss : [0.44982507824897766] Precision : [0.6875] Recall: [0.4399999976158142] AUC : [0.7952112555503845]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 93 Acc : [0.8333333730697632] Loss : [0.3434242606163025] Precision : [0.5882353186607361] Recall: [0.5263158082962036] AUC : [0.9025974273681641]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 94 Acc : [0.8541666865348816] Loss : [0.41588008403778076] Precision : [0.8125] Recall: [0.5416666865348816] AUC : [0.8521412014961243]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 95 Acc : [0.8229166269302368] Loss : [0.4193977415561676] Precision : [0.6875] Recall: [0.47826087474823] AUC : [0.8257891535758972]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 96 Acc : [0.8229166865348816] Loss : [0.43015316128730774] Precision : [0.625] Recall: [0.4761904776096344] AUC : [0.8123809695243835]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 97 Acc : [0.78125] Loss : [0.41721102595329285] Precision : [0.5] Recall: [0.380952388048172] AUC : [0.835873007774353]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 98 Acc : [0.84375] Loss : [0.3712114095687866] Precision : [0.6875] Recall: [0.523809552192688] AUC : [0.8533333539962769]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 99 Acc : [0.8125] Loss : [0.3495334982872009] Precision : [0.625] Recall: [0.4545454680919647] AUC : [0.8799140453338623]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 100 Acc : [0.8125] Loss : [0.4310639798641205] Precision : [0.625] Recall: [0.4545454680919647] AUC : [0.8243243098258972]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 101 Acc : [0.7916666269302368] Loss : [0.45265135169029236] Precision : [0.625] Recall: [0.4166666567325592] AUC : [0.8301504850387573]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 102 Acc : [0.7916666269302368] Loss : [0.565684974193573] Precision : [0.8125] Recall: [0.4333333373069763] AUC : [0.7979798316955566]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 103 Acc : [0.7916666269302368] Loss : [0.3936866521835327] Precision : [0.5625] Recall: [0.40909090638160706] AUC : [0.8436732292175293]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 104 Acc : [0.78125] Loss : [0.45806893706321716] Precision : [0.5625] Recall: [0.3913043439388275] AUC : [0.7706968188285828]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 105 Acc : [0.8333333134651184] Loss : [0.3825976252555847] Precision : [0.6875] Recall: [0.5] AUC : [0.8329238891601562]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 106 Acc : [0.8229166865348816] Loss : [0.37989363074302673] Precision : [0.625] Recall: [0.4761904776096344] AUC : [0.8600000143051147]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 107 Acc : [0.7708333134651184] Loss : [0.5137945413589478] Precision : [0.5882353186607361] Recall: [0.4000000059604645] AUC : [0.7352112531661987]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 108 Acc : [0.7916666269302368] Loss : [0.5263903737068176] Precision : [0.7333333492279053] Recall: [0.40740740299224854] AUC : [0.7769726514816284]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 109 Acc : [0.7916666865348816] Loss : [0.3841181695461273] Precision : [0.4375] Recall: [0.3888888955116272] AUC : [0.7930911779403687]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 110 Acc : [0.8020833730697632] Loss : [0.39275890588760376] Precision : [0.5] Recall: [0.42105263471603394] AUC : [0.8212577104568481]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 111 Acc : [0.8020833730697632] Loss : [0.4502328634262085] Precision : [0.6875] Recall: [0.4399999976158142] AUC : [0.812957763671875]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 112 Acc : [0.8020833730697632] Loss : [0.4060342609882355] Precision : [0.5625] Recall: [0.4285714328289032] AUC : [0.858730137348175]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 113 Acc : [0.8645833134651184] Loss : [0.37434470653533936] Precision : [0.75] Recall: [0.5714285969734192] AUC : [0.8822221755981445]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 114 Acc : [0.8125] Loss : [0.3514501452445984] Precision : [0.5625] Recall: [0.44999998807907104] AUC : [0.8858552575111389]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 115 Acc : [0.78125] Loss : [0.38731545209884644] Precision : [0.5] Recall: [0.380952388048172] AUC : [0.8476190567016602]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 116 Acc : [0.7916666269302368] Loss : [0.44098469614982605] Precision : [0.625] Recall: [0.4166666567325592] AUC : [0.8133680820465088]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 117 Acc : [0.7604166269302368] Loss : [0.38527244329452515] Precision : [0.4375] Recall: [0.3333333432674408] AUC : [0.8333333730697632]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 118 Acc : [0.7291666865348816] Loss : [0.38055577874183655] Precision : [0.3125] Recall: [0.25] AUC : [0.82039475440979]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 119 Acc : [0.8333333730697632] Loss : [0.4885472059249878] Precision : [0.75] Recall: [0.5] AUC : [0.7734375]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 120 Acc : [0.7395833730697632] Loss : [0.6135704517364502] Precision : [0.625] Recall: [0.3448275923728943] AUC : [0.7496139407157898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 121 Acc : [0.8541666865348816] Loss : [0.29377657175064087] Precision : [0.625] Recall: [0.5555555820465088] AUC : [0.9077635407447815]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 122 Acc : [0.8020833730697632] Loss : [0.4149171710014343] Precision : [0.5625] Recall: [0.4285714328289032] AUC : [0.8114286065101624]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 123 Acc : [0.78125] Loss : [0.47038280963897705] Precision : [0.6000000238418579] Recall: [0.375] AUC : [0.7960069179534912]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 124 Acc : [0.8020833134651184] Loss : [0.40784120559692383] Precision : [0.6666666865348816] Recall: [0.3478260934352875] AUC : [0.8379988670349121]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 125 Acc : [0.75] Loss : [0.5266880989074707] Precision : [0.6363636255264282] Recall: [0.25925925374031067] AUC : [0.7603328227996826]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 126 Acc : [0.75] Loss : [0.5192261338233948] Precision : [0.5833333134651184] Recall: [0.26923078298568726] AUC : [0.7758241891860962]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 127 Acc : [0.8020833134651184] Loss : [0.4229791760444641] Precision : [0.6153846383094788] Recall: [0.3636363744735718] AUC : [0.8227887153625488]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 128 Acc : [0.75] Loss : [0.46875110268592834] Precision : [0.5] Recall: [0.25] AUC : [0.7705440521240234]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 129 Acc : [0.84375] Loss : [0.3823002576828003] Precision : [0.692307710647583] Recall: [0.44999998807907104] AUC : [0.8720394372940063]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 130 Acc : [0.78125] Loss : [0.4006519317626953] Precision : [0.46666666865348816] Recall: [0.3499999940395355] AUC : [0.8095394372940063]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 131 Acc : [0.8333333134651184] Loss : [0.3818894028663635] Precision : [0.7692307829856873] Recall: [0.43478259444236755] AUC : [0.889517605304718]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 132 Acc : [0.8229166865348816] Loss : [0.45657670497894287] Precision : [0.7692307829856873] Recall: [0.4166666567325592] AUC : [0.8072916269302368]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 133 Acc : [0.8020833730697632] Loss : [0.4545624256134033] Precision : [0.6470588445663452] Recall: [0.4583333432674408] AUC : [0.813368022441864]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 134 Acc : [0.8125] Loss : [0.4081978499889374] Precision : [0.625] Recall: [0.4545454680919647] AUC : [0.8418304920196533]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 135 Acc : [0.8333333730697632] Loss : [0.33992403745651245] Precision : [0.5] Recall: [0.5] AUC : [0.8832031488418579]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 136 Acc : [0.75] Loss : [0.46457022428512573] Precision : [0.5] Recall: [0.3333333432674408] AUC : [0.7844328880310059]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 137 Acc : [0.7708333730697632] Loss : [0.5326073169708252] Precision : [0.6875] Recall: [0.3928571343421936] AUC : [0.7439601421356201]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 138 Acc : [0.7708333730697632] Loss : [0.5193920135498047] Precision : [0.625] Recall: [0.38461539149284363] AUC : [0.7554944753646851]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 139 Acc : [0.8229166865348816] Loss : [0.4505256414413452] Precision : [0.75] Recall: [0.47999998927116394] AUC : [0.8022534847259521]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 140 Acc : [0.7604166269302368] Loss : [0.4414660632610321] Precision : [0.5] Recall: [0.3478260934352875] AUC : [0.8004764914512634]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 141 Acc : [0.78125] Loss : [0.47231507301330566] Precision : [0.6875] Recall: [0.40740740299224854] AUC : [0.8040794134140015]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 142 Acc : [0.8333333134651184] Loss : [0.35773688554763794] Precision : [0.75] Recall: [0.5] AUC : [0.8833912014961243]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 143 Acc : [0.8333333730697632] Loss : [0.3796387016773224] Precision : [0.6875] Recall: [0.5] AUC : [0.8593366146087646]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 144 Acc : [0.8125] Loss : [0.38837698101997375] Precision : [0.625] Recall: [0.4545454680919647] AUC : [0.8525798320770264]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 145 Acc : [0.78125] Loss : [0.46088743209838867] Precision : [0.5625] Recall: [0.3913043439388275] AUC : [0.7817152738571167]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 146 Acc : [0.8229166269302368] Loss : [0.4587966501712799] Precision : [0.75] Recall: [0.47999998927116394] AUC : [0.811830997467041]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 147 Acc : [0.78125] Loss : [0.39371663331985474] Precision : [0.4375] Recall: [0.3684210479259491] AUC : [0.8390293717384338]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 148 Acc : [0.8020833134651184] Loss : [0.4832748770713806] Precision : [0.75] Recall: [0.4444444477558136] AUC : [0.7793880701065063]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 149 Acc : [0.7395833730697632] Loss : [0.4993818998336792] Precision : [0.4375] Recall: [0.30434781312942505] AUC : [0.7373436689376831]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 150 Acc : [0.8020833730697632] Loss : [0.3847544193267822] Precision : [0.5625] Recall: [0.4285714328289032] AUC : [0.8409523963928223]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 151 Acc : [0.7916666865348816] Loss : [0.5088701248168945] Precision : [0.8125] Recall: [0.4333333373069763] AUC : [0.7901514768600464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 152 Acc : [0.7604166865348816] Loss : [0.48995304107666016] Precision : [0.625] Recall: [0.37037035822868347] AUC : [0.773751974105835]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 153 Acc : [0.78125] Loss : [0.40426158905029297] Precision : [0.5] Recall: [0.380952388048172] AUC : [0.8396825194358826]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 154 Acc : [0.7604166269302368] Loss : [0.45699629187583923] Precision : [0.5625] Recall: [0.36000001430511475] AUC : [0.7923943996429443]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 155 Acc : [0.78125] Loss : [0.4563865661621094] Precision : [0.625] Recall: [0.4000000059604645] AUC : [0.8030985593795776]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 156 Acc : [0.8229166865348816] Loss : [0.39134877920150757] Precision : [0.625] Recall: [0.4761904776096344] AUC : [0.8311110734939575]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 157 Acc : [0.7708333730697632] Loss : [0.3975412845611572] Precision : [0.4375] Recall: [0.3499999940395355] AUC : [0.8213815689086914]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 158 Acc : [0.8229166269302368] Loss : [0.3553265929222107] Precision : [0.6875] Recall: [0.47826087474823] AUC : [0.8802858591079712]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 159 Acc : [0.7708333134651184] Loss : [0.44267764687538147] Precision : [0.5625] Recall: [0.375] AUC : [0.8015046119689941]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 160 Acc : [0.8020833730697632] Loss : [0.44381222128868103] Precision : [0.6875] Recall: [0.4399999976158142] AUC : [0.8084506988525391]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 161 Acc : [0.84375] Loss : [0.36725789308547974] Precision : [0.6875] Recall: [0.523809552192688] AUC : [0.8730158805847168]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 162 Acc : [0.8229166865348816] Loss : [0.3625872731208801] Precision : [0.625] Recall: [0.4761904776096344] AUC : [0.879365086555481]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 163 Acc : [0.8020833730697632] Loss : [0.39854753017425537] Precision : [0.5625] Recall: [0.4285714328289032] AUC : [0.8171428442001343]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 164 Acc : [0.8229166865348816] Loss : [0.3779903054237366] Precision : [0.625] Recall: [0.4761904776096344] AUC : [0.8577777147293091]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 165 Acc : [0.75] Loss : [0.47713208198547363] Precision : [0.5625] Recall: [0.3461538553237915] AUC : [0.7840659022331238]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 166 Acc : [0.75] Loss : [0.44664621353149414] Precision : [0.375] Recall: [0.30000001192092896] AUC : [0.777302622795105]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 167 Acc : [0.8854166269302368] Loss : [0.33690887689590454] Precision : [0.875] Recall: [0.6086956262588501] AUC : [0.9032161831855774]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 168 Acc : [0.7083333730697632] Loss : [0.6364821195602417] Precision : [0.5625] Recall: [0.30000001192092896] AUC : [0.7484848499298096]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 169 Acc : [0.7708333730697632] Loss : [0.5212093591690063] Precision : [0.6875] Recall: [0.3928571343421936] AUC : [0.7691701650619507]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 170 Acc : [0.8020833730697632] Loss : [0.35446006059646606] Precision : [0.5333333611488342] Recall: [0.4000000059604645] AUC : [0.8648025989532471]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 171 Acc : [0.8229166865348816] Loss : [0.3761059045791626] Precision : [0.7058823704719543] Recall: [0.5] AUC : [0.8758680820465088]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 172 Acc : [0.7708333134651184] Loss : [0.4920309782028198] Precision : [0.6875] Recall: [0.3928571343421936] AUC : [0.7825630307197571]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 173 Acc : [0.8020833730697632] Loss : [0.38094401359558105] Precision : [0.5333333611488342] Recall: [0.4000000059604645] AUC : [0.8480262756347656]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 174 Acc : [0.7916666865348816] Loss : [0.40152186155319214] Precision : [0.5714285969734192] Recall: [0.3636363744735718] AUC : [0.8310810327529907]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 175 Acc : [0.8020833730697632] Loss : [0.41994816064834595] Precision : [0.7692307829856873] Recall: [0.38461539149284363] AUC : [0.8590659499168396]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 176 Acc : [0.8020833730697632] Loss : [0.37840569019317627] Precision : [0.625] Recall: [0.43478259444236755] AUC : [0.8871352076530457]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 177 Acc : [0.7708333730697632] Loss : [0.4842730462551117] Precision : [0.6000000238418579] Recall: [0.36000001430511475] AUC : [0.7783098220825195]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 178 Acc : [0.75] Loss : [0.5089497566223145] Precision : [0.6428571343421936] Recall: [0.3214285671710968] AUC : [0.7804621458053589]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 179 Acc : [0.8125] Loss : [0.42588353157043457] Precision : [0.75] Recall: [0.4615384638309479] AUC : [0.8486263751983643]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 180 Acc : [0.84375] Loss : [0.4100404977798462] Precision : [0.75] Recall: [0.52173912525177] AUC : [0.846337080001831]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 181 Acc : [0.8020833134651184] Loss : [0.356867253780365] Precision : [0.625] Recall: [0.43478259444236755] AUC : [0.9234663844108582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 182 Acc : [0.7708333730697632] Loss : [0.44846609234809875] Precision : [0.5625] Recall: [0.375] AUC : [0.8162615299224854]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 183 Acc : [0.7708333730697632] Loss : [0.5405809283256531] Precision : [0.6875] Recall: [0.3928571343421936] AUC : [0.7602416276931763]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 184 Acc : [0.8125] Loss : [0.3771539032459259] Precision : [0.5625] Recall: [0.44999998807907104] AUC : [0.8641446828842163]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 185 Acc : [0.8125] Loss : [0.3835486173629761] Precision : [0.5882353186607361] Recall: [0.4761904776096344] AUC : [0.8511111736297607]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 186 Acc : [0.7916666269302368] Loss : [0.5103079080581665] Precision : [0.75] Recall: [0.4285714328289032] AUC : [0.7649685144424438]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 187 Acc : [0.78125] Loss : [0.4162578582763672] Precision : [0.5625] Recall: [0.3913043439388275] AUC : [0.8260869383811951]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 188 Acc : [0.8125] Loss : [0.43306970596313477] Precision : [0.625] Recall: [0.4545454680919647] AUC : [0.8015970587730408]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 189 Acc : [0.75] Loss : [0.403153657913208] Precision : [0.4375] Recall: [0.3181818127632141] AUC : [0.8442875146865845]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 190 Acc : [0.7708333730697632] Loss : [0.47788888216018677] Precision : [0.5625] Recall: [0.375] AUC : [0.7595486044883728]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 191 Acc : [0.7395833730697632] Loss : [0.4752088189125061] Precision : [0.5] Recall: [0.3199999928474426] AUC : [0.783661961555481]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 192 Acc : [0.84375] Loss : [0.39153414964675903] Precision : [0.7222222089767456] Recall: [0.5652173757553101] AUC : [0.8642048835754395]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 193 Acc : [0.8333333730697632] Loss : [0.4531401991844177] Precision : [0.75] Recall: [0.5] AUC : [0.8075810074806213]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 194 Acc : [0.8020833730697632] Loss : [0.5751818418502808] Precision : [0.875] Recall: [0.4516128897666931] AUC : [0.7575682401657104]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 195 Acc : [0.7395833730697632] Loss : [0.4537895619869232] Precision : [0.5] Recall: [0.3199999928474426] AUC : [0.7943662405014038]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 196 Acc : [0.7604166865348816] Loss : [0.45967671275138855] Precision : [0.5882353186607361] Recall: [0.38461539149284363] AUC : [0.7939560413360596]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 197 Acc : [0.8541666865348816] Loss : [0.3786603808403015] Precision : [0.7368420958518982] Recall: [0.6086956262588501] AUC : [0.8719475865364075]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 198 Acc : [0.7708333134651184] Loss : [0.40358465909957886] Precision : [0.4444444477558136] Recall: [0.4000000059604645] AUC : [0.8236842155456543]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 199 Acc : [0.8645833134651184] Loss : [0.37588635087013245] Precision : [0.7894737124443054] Recall: [0.625] AUC : [0.9062500596046448]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 200 Acc : [0.78125] Loss : [0.40286025404930115] Precision : [0.5714285969734192] Recall: [0.5] AUC : [0.8614004850387573]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 201 Acc : [0.8020833134651184] Loss : [0.36441487073898315] Precision : [0.5] Recall: [0.6315789222717285] AUC : [0.8684210777282715]\n",
      "dict_keys(['loss', 'accuracy', 'precision', 'recall', 'AUC', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_AUC'])\n",
      "Batch : 202 Acc : [0.78125] Loss : [0.31964462995529175] Precision : [0.4285714328289032] Recall: [0.5] AUC : [0.8700141906738281]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e065a842ffa5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                 \u001b[0mvalidation_batch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                                 verbose=0)\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "STEPS_PER_EPOCH=len(image_dataset)/16\n",
    "\n",
    "for epoch in range(EPOCHS) :\n",
    "    print()\n",
    "    print()\n",
    "    print(\"Epoch :\",epoch)\n",
    "    print()\n",
    "    print()\n",
    "    \n",
    "    batch = 0\n",
    "    for (batch_img, batch_label), (val_img, val_label) in zip(datagen.flow(image_dataset, labels, batch_size=16, subset='training'),\n",
    "               datagen.flow(image_dataset, labels, batch_size=8, subset='validation')):\n",
    "            history = model.fit(batch_img, batch_label, \n",
    "                                batch_size=16,\n",
    "                                validation_data=(val_img, val_label), \n",
    "                                validation_batch_size=8,\n",
    "                                verbose=0)\n",
    "            print(history.history.keys())\n",
    "            acc = history.history['accuracy']\n",
    "            loss = history.history['loss']\n",
    "#             val_acc = history.history['val_acc']\n",
    "#             val_loss = history.history['val_loss']\n",
    "            precision = history.history['precision']\n",
    "#             val_precision = history.history['val_precision']\n",
    "            recall = history.history['recall']\n",
    "#             val_recall = history.history['val_recall']\n",
    "            AUC = history.history['AUC']\n",
    "#             val_AUC = history.history['val_AUC']\n",
    "            print(\"Batch : {} Acc : {} Loss : {} Precision : {} Recall: {} AUC : {}\".format(batch ,acc, loss, precision, recall, AUC))\n",
    "            batch += 1\n",
    "            \n",
    "            if batch >= STEPS_PER_EPOCH :\n",
    "                break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08047846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d6bfc373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_47 (Conv2D)           (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 297,674\n",
      "Trainable params: 297,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential, layers, activations\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(layers.Conv2D(64, 3, padding='same', input_shape=(256,256,3)))\n",
    "model2.add(layers.LeakyReLU(alpha=0.01))\n",
    "model2.add(layers.MaxPool2D())\n",
    "\n",
    "model2.add(layers.Conv2D(128, 3, padding='same'))\n",
    "model2.add(layers.LeakyReLU(alpha=0.01))\n",
    "model2.add(layers.MaxPool2D())\n",
    "\n",
    "model2.add(layers.Conv2D(128, 3, padding='same'))\n",
    "model2.add(layers.LeakyReLU(alpha=0.01))\n",
    "model2.add(layers.MaxPool2D())\n",
    "\n",
    "model2.add(layers.Conv2D(64, 3, padding='same'))\n",
    "model2.add(layers.LeakyReLU(alpha=0.01))\n",
    "\n",
    "model2.add(layers.GlobalAveragePooling2D())\n",
    "model2.add(layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "model2.summary()\n",
    "metrics =[\n",
    "    tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision'),\n",
    "    tf.keras.metrics.Recall(name='recall'),\n",
    "    tf.keras.metrics.AUC(name='AUC')\n",
    "]\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint('./ckpt_test/cp.ckpt',\n",
    "                                      save_weights_only=True,\n",
    "                                      save_freq='epoch'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='accuracy',\n",
    "                                        patience=3,\n",
    "                                        factor=0.01,\n",
    "                                        min_lr=1e-13)\n",
    "]\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc4342e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs :  0\n",
      "0\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9181WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"conv2d_47_input:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.1765 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9181 - val_loss: 0.1600 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9661\n",
      "1\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1478 - accuracy: 0.9406 - precision: 0.9333 - recall: 0.4375 - AUC: 0.9547 - val_loss: 0.1556 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9575\n",
      "2\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1974 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9091 - val_loss: 0.1820 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9201\n",
      "3\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1827 - accuracy: 0.9406 - precision: 0.7826 - recall: 0.5625 - AUC: 0.9107 - val_loss: 0.1438 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9688\n",
      "4\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2037 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9003 - val_loss: 0.2479 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8490\n",
      "5\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1723 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9344 - val_loss: 0.1757 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9280\n",
      "6\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2036 - accuracy: 0.9125 - precision: 0.6111 - recall: 0.3438 - AUC: 0.9003 - val_loss: 0.1995 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8993\n",
      "7\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1913 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9089 - val_loss: 0.1644 - val_accuracy: 0.9125 - val_precision: 0.5556 - val_recall: 0.6250 - val_AUC: 0.9557\n",
      "8\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2098 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.8821 - val_loss: 0.1899 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9028\n",
      "9\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.1805 - accuracy: 0.9469 - precision: 0.9412 - recall: 0.5000 - AUC: 0.9187 - val_loss: 0.1186 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9722\n",
      "10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1701 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9287 - val_loss: 0.2035 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.9123\n",
      "11\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1929 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9087 - val_loss: 0.1381 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9635\n",
      "12\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1662 - accuracy: 0.9406 - precision: 0.7826 - recall: 0.5625 - AUC: 0.9340 - val_loss: 0.1642 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9523\n",
      "13\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1376 - accuracy: 0.9438 - precision: 0.8889 - recall: 0.5000 - AUC: 0.9635 - val_loss: 0.1279 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9627\n",
      "14\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1814 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9183 - val_loss: 0.2469 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8446\n",
      "15\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1797 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9271 - val_loss: 0.1792 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9253\n",
      "16\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1764 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9301 - val_loss: 0.3147 - val_accuracy: 0.8500 - val_precision: 0.1667 - val_recall: 0.1250 - val_AUC: 0.8082\n",
      "17\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1954 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9087 - val_loss: 0.1651 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9418\n",
      "18\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1638 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9343 - val_loss: 0.1796 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9089\n",
      "19\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1743 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9325 - val_loss: 0.1860 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9401\n",
      "20\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1769 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9287 - val_loss: 0.2753 - val_accuracy: 0.8500 - val_precision: 0.2500 - val_recall: 0.2500 - val_AUC: 0.8516\n",
      "21\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1961 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9154 - val_loss: 0.3191 - val_accuracy: 0.8875 - val_precision: 0.4286 - val_recall: 0.3750 - val_AUC: 0.8108\n",
      "22\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1542 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9412 - val_loss: 0.1272 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9818\n",
      "23\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2126 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.8965 - val_loss: 0.2185 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8628\n",
      "24\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1961 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.8967 - val_loss: 0.1422 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9670\n",
      "25\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1994 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.8889 - val_loss: 0.1877 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9227\n",
      "26\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1893 - accuracy: 0.9219 - precision: 0.6522 - recall: 0.4688 - AUC: 0.9186 - val_loss: 0.0947 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9931\n",
      "27\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1279 - accuracy: 0.9531 - precision: 0.8696 - recall: 0.6250 - AUC: 0.9660 - val_loss: 0.2330 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8750\n",
      "28\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2151 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.8903 - val_loss: 0.1843 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9271\n",
      "29\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2366 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.8742 - val_loss: 0.2440 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8498\n",
      "30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1848 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9261 - val_loss: 0.1762 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9306\n",
      "31\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2081 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9047 - val_loss: 0.1121 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1765 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9262 - val_loss: 0.2286 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8741\n",
      "33\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1818 - accuracy: 0.9281 - precision: 0.8462 - recall: 0.3438 - AUC: 0.9352 - val_loss: 0.1978 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8845\n",
      "34\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2001 - accuracy: 0.9187 - precision: 0.7500 - recall: 0.2812 - AUC: 0.9026 - val_loss: 0.2750 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8099\n",
      "35\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1616 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9454 - val_loss: 0.1510 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9540\n",
      "36\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2157 - accuracy: 0.9062 - precision: 0.6000 - recall: 0.1875 - AUC: 0.9028 - val_loss: 0.2382 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8438\n",
      "37\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1471 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9634 - val_loss: 0.2360 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8915\n",
      "38\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1483 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9657 - val_loss: 0.2505 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8351\n",
      "39\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1883 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9112 - val_loss: 0.2186 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8403\n",
      "40\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1432 - accuracy: 0.9531 - precision: 0.9474 - recall: 0.5625 - AUC: 0.9551 - val_loss: 0.1397 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9627\n",
      "41\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1333 - accuracy: 0.9563 - precision: 0.9500 - recall: 0.5938 - AUC: 0.9590 - val_loss: 0.1747 - val_accuracy: 0.9250 - val_precision: 0.6250 - val_recall: 0.6250 - val_AUC: 0.9323\n",
      "42\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1566 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9469 - val_loss: 0.1735 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9314\n",
      "43\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1866 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9255 - val_loss: 0.2175 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9097\n",
      "44\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1790 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9259 - val_loss: 0.1172 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9826\n",
      "45\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1737 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9360 - val_loss: 0.2164 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9271\n",
      "46\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2153 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9085 - val_loss: 0.1834 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8872\n",
      "47\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1961 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9043 - val_loss: 0.1701 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9323\n",
      "48\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1445 - accuracy: 0.9344 - precision: 0.7037 - recall: 0.5938 - AUC: 0.9600 - val_loss: 0.1399 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9705\n",
      "49\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1807 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9236 - val_loss: 0.0878 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9861\n",
      "50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1400 - accuracy: 0.9562 - precision: 0.8750 - recall: 0.6562 - AUC: 0.9510 - val_loss: 0.1660 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9557\n",
      "51\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1779 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9222 - val_loss: 0.1110 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9818\n",
      "52\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1759 - accuracy: 0.9438 - precision: 0.8889 - recall: 0.5000 - AUC: 0.9237 - val_loss: 0.2150 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9193\n",
      "53\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1874 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9123 - val_loss: 0.1799 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9280\n",
      "54\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1703 - accuracy: 0.9312 - precision: 0.9167 - recall: 0.3438 - AUC: 0.9376 - val_loss: 0.1456 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9609\n",
      "55\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1629 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9393 - val_loss: 0.2860 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8038\n",
      "56\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2042 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.8922 - val_loss: 0.2231 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.8602\n",
      "57\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2481 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8271 - val_loss: 0.2139 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8906\n",
      "58\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1813 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9226 - val_loss: 0.1398 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9731\n",
      "59\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1475 - accuracy: 0.9594 - precision: 0.8800 - recall: 0.6875 - AUC: 0.9454 - val_loss: 0.1539 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9618\n",
      "60\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1352 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9677 - val_loss: 0.1805 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9054\n",
      "61\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1770 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9360 - val_loss: 0.2138 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8672\n",
      "62\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1755 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9449 - val_loss: 0.2365 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8837\n",
      "63\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1350 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.5312 - AUC: 0.9607 - val_loss: 0.1228 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9748\n",
      "64\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1628 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9530 - val_loss: 0.1462 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9688\n",
      "65\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1611 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9398 - val_loss: 0.1266 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9618\n",
      "66\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1856 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9230 - val_loss: 0.2182 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8793\n",
      "67\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2204 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.8770 - val_loss: 0.1427 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9462\n",
      "68\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1488 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9619 - val_loss: 0.1320 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9618\n",
      "69\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1772 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9267 - val_loss: 0.2330 - val_accuracy: 0.8625 - val_precision: 0.2000 - val_recall: 0.1250 - val_AUC: 0.9002\n",
      "70\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1610 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9441 - val_loss: 0.1668 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9410\n",
      "71\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1937 - accuracy: 0.9156 - precision: 0.6190 - recall: 0.4062 - AUC: 0.9226 - val_loss: 0.1501 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9644\n",
      "72\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2089 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.8867 - val_loss: 0.2419 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9097\n",
      "73\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1922 - accuracy: 0.9094 - precision: 0.5652 - recall: 0.4062 - AUC: 0.9172 - val_loss: 0.0777 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9965\n",
      "74\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2211 - accuracy: 0.9000 - precision: 0.5000 - recall: 0.2188 - AUC: 0.8951 - val_loss: 0.1610 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9332\n",
      "75\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1602 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9472 - val_loss: 0.2205 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8802\n",
      "76\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2423 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.8472 - val_loss: 0.1385 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9670\n",
      "77\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1930 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9220 - val_loss: 0.1726 - val_accuracy: 0.9250 - val_precision: 0.6250 - val_recall: 0.6250 - val_AUC: 0.9410\n",
      "78\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2276 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.8801 - val_loss: 0.2089 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9019\n",
      "79\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1669 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9408 - val_loss: 0.1065 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9896\n",
      "80\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2239 - accuracy: 0.9125 - precision: 0.5909 - recall: 0.4062 - AUC: 0.8932 - val_loss: 0.2167 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8681\n",
      "81\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1667 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9449 - val_loss: 0.1383 - val_accuracy: 0.9250 - val_precision: 0.6000 - val_recall: 0.7500 - val_AUC: 0.9722\n",
      "82\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1537 - accuracy: 0.9438 - precision: 0.7917 - recall: 0.5938 - AUC: 0.9514 - val_loss: 0.2373 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8359\n",
      "83\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2022 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.8923 - val_loss: 0.1581 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9427\n",
      "84\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2114 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.8907 - val_loss: 0.1616 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9557\n",
      "85\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1897 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9093 - val_loss: 0.1646 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9158\n",
      "86\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1943 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9125 - val_loss: 0.1395 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9479\n",
      "87\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1892 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9149 - val_loss: 0.1460 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9549\n",
      "88\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1732 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9337 - val_loss: 0.1637 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9323\n",
      "89\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1730 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9351 - val_loss: 0.2187 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8872\n",
      "90\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1984 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9141 - val_loss: 0.2019 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.8976\n",
      "91\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1734 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9392 - val_loss: 0.2122 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8993\n",
      "92\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1939 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.9120 - val_loss: 0.2152 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8724\n",
      "93\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1846 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9200 - val_loss: 0.1660 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9844\n",
      "94\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1541 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9600 - val_loss: 0.2158 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8924\n",
      "95\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1369 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9721 - val_loss: 0.1699 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9531\n",
      "96\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2118 - accuracy: 0.9156 - precision: 0.7273 - recall: 0.2500 - AUC: 0.8961 - val_loss: 0.2580 - val_accuracy: 0.8875 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8455\n",
      "97\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2716 - accuracy: 0.9062 - precision: 0.5556 - recall: 0.3125 - AUC: 0.8285 - val_loss: 0.2075 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.9062\n",
      "98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1379 - accuracy: 0.9406 - precision: 0.8824 - recall: 0.4688 - AUC: 0.9652 - val_loss: 0.1784 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9297\n",
      "99\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2667 - accuracy: 0.9062 - precision: 0.5714 - recall: 0.2500 - AUC: 0.8370 - val_loss: 0.2260 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8681\n",
      "100\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1854 - accuracy: 0.9406 - precision: 0.9333 - recall: 0.4375 - AUC: 0.9193 - val_loss: 0.1770 - val_accuracy: 0.9250 - val_precision: 0.6250 - val_recall: 0.6250 - val_AUC: 0.9418\n",
      "101\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1822 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9121 - val_loss: 0.2420 - val_accuracy: 0.9000 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8689\n",
      "102\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2269 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.8661 - val_loss: 0.1470 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9332\n",
      "103\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2254 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8740 - val_loss: 0.0982 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9792\n",
      "104\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2611 - accuracy: 0.8937 - precision: 0.4375 - recall: 0.2188 - AUC: 0.8669 - val_loss: 0.2251 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8976\n",
      "105\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1452 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9559 - val_loss: 0.2385 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8715\n",
      "106\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1679 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9427 - val_loss: 0.3031 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8064\n",
      "107\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1803 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9364 - val_loss: 0.1368 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9826\n",
      "108\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1944 - accuracy: 0.9094 - precision: 0.6000 - recall: 0.2812 - AUC: 0.9166 - val_loss: 0.1182 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9722\n",
      "109\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1716 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9335 - val_loss: 0.2122 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.9253\n",
      "110\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2101 - accuracy: 0.9156 - precision: 0.6667 - recall: 0.3125 - AUC: 0.9021 - val_loss: 0.2266 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8585\n",
      "111\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1462 - accuracy: 0.9406 - precision: 0.7826 - recall: 0.5625 - AUC: 0.9561 - val_loss: 0.1428 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9618\n",
      "112\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1847 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9241 - val_loss: 0.1319 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9653\n",
      "113\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2050 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9045 - val_loss: 0.1666 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9002\n",
      "114\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2700 - accuracy: 0.8969 - precision: 0.4737 - recall: 0.2812 - AUC: 0.8448 - val_loss: 0.1869 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9097\n",
      "115\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1718 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9389 - val_loss: 0.1436 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9505\n",
      "116\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2321 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.8644 - val_loss: 0.2329 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8872\n",
      "117\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2060 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.9039 - val_loss: 0.2162 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8672\n",
      "118\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2087 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.8945 - val_loss: 0.1928 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9349\n",
      "119\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2132 - accuracy: 0.9094 - precision: 0.5714 - recall: 0.3750 - AUC: 0.9012 - val_loss: 0.1303 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9627\n",
      "120\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2075 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9073 - val_loss: 0.1653 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9549\n",
      "121\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1819 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9212 - val_loss: 0.1628 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9635\n",
      "122\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 0.2016 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.9037 - val_loss: 0.1804 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9054\n",
      "123\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2385 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.8573 - val_loss: 0.1567 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9549\n",
      "124\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1383 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9710 - val_loss: 0.1945 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9132\n",
      "125\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1690 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9430 - val_loss: 0.2248 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8576\n",
      "126\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1844 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.9314 - val_loss: 0.2606 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8099\n",
      "127\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1532 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9511 - val_loss: 0.1868 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8915\n",
      "128\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1846 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9195 - val_loss: 0.2198 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8733\n",
      "129\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1824 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9278 - val_loss: 0.1503 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9384\n",
      "130\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2467 - accuracy: 0.8969 - precision: 0.4737 - recall: 0.2812 - AUC: 0.8494 - val_loss: 0.0926 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9896\n",
      "131\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2340 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.8617 - val_loss: 0.1781 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9323\n",
      "132\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1947 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9210 - val_loss: 0.2266 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8993\n",
      "133\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1933 - accuracy: 0.9469 - precision: 1.0000 - recall: 0.4688 - AUC: 0.8885 - val_loss: 0.1782 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9323\n",
      "134\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1809 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9373 - val_loss: 0.1500 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9427\n",
      "135\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1796 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9191 - val_loss: 0.1114 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9792\n",
      "136\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2004 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.8927 - val_loss: 0.2050 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8941\n",
      "137\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1636 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9470 - val_loss: 0.1575 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9531\n",
      "138\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1820 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9167 - val_loss: 0.1445 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9410\n",
      "139\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1828 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9296 - val_loss: 0.1532 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9592\n",
      "140\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2191 - accuracy: 0.9156 - precision: 0.6923 - recall: 0.2812 - AUC: 0.8775 - val_loss: 0.1582 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9661\n",
      "141\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1748 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9326 - val_loss: 0.2071 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8915\n",
      "142\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1970 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.8951 - val_loss: 0.2845 - val_accuracy: 0.8500 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8351\n",
      "143\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1949 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9095 - val_loss: 0.3515 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.7214\n",
      "144\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1591 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9487 - val_loss: 0.2009 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9436\n",
      "145\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1703 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9454 - val_loss: 0.1906 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9045\n",
      "146\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1791 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.9343 - val_loss: 0.2183 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9010\n",
      "147\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1416 - accuracy: 0.9500 - precision: 0.9000 - recall: 0.5625 - AUC: 0.9622 - val_loss: 0.1574 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9349\n",
      "148\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1562 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9538 - val_loss: 0.1048 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9983\n",
      "149\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2257 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.8837 - val_loss: 0.1970 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9054\n",
      "150\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1884 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9070 - val_loss: 0.2104 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8984\n",
      "151\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1860 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9145 - val_loss: 0.1329 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9661\n",
      "152\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1870 - accuracy: 0.9250 - precision: 0.6667 - recall: 0.5000 - AUC: 0.9280 - val_loss: 0.1632 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9245\n",
      "153\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1316 - accuracy: 0.9531 - precision: 0.8696 - recall: 0.6250 - AUC: 0.9657 - val_loss: 0.2495 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8281\n",
      "154\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1932 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.9060 - val_loss: 0.1832 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9158\n",
      "155\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1321 - accuracy: 0.9437 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9664 - val_loss: 0.1252 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9705\n",
      "156\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1859 - accuracy: 0.9281 - precision: 0.6800 - recall: 0.5312 - AUC: 0.9169 - val_loss: 0.2182 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8845\n",
      "157\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1700 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9397 - val_loss: 0.2053 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9045\n",
      "158\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2037 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.8989 - val_loss: 0.1281 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9661\n",
      "159\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2093 - accuracy: 0.9219 - precision: 0.6522 - recall: 0.4688 - AUC: 0.8886 - val_loss: 0.1986 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9201\n",
      "160\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2196 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.8874 - val_loss: 0.2110 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8681\n",
      "161\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1917 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9034 - val_loss: 0.2320 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8663\n",
      "162\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1952 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.9046 - val_loss: 0.1245 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9861\n",
      "163\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1386 - accuracy: 0.9438 - precision: 0.7917 - recall: 0.5938 - AUC: 0.9614 - val_loss: 0.1513 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9618\n",
      "164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1858 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.9153 - val_loss: 0.1577 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9479\n",
      "165\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1361 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9712 - val_loss: 0.1653 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9497\n",
      "166\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1429 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9618 - val_loss: 0.2085 - val_accuracy: 0.9125 - val_precision: 1.0000 - val_recall: 0.1250 - val_AUC: 0.9045\n",
      "167\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1483 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9525 - val_loss: 0.1223 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9635\n",
      "168\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1688 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9284 - val_loss: 0.1739 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9401\n",
      "169\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1986 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.8964 - val_loss: 0.1725 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9410\n",
      "170\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1856 - accuracy: 0.9250 - precision: 0.6667 - recall: 0.5000 - AUC: 0.9131 - val_loss: 0.1703 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9210\n",
      "171\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1733 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9339 - val_loss: 0.2859 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8116\n",
      "172\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1858 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9131 - val_loss: 0.2707 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8438\n",
      "173\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2203 - accuracy: 0.8969 - precision: 0.4706 - recall: 0.2500 - AUC: 0.8812 - val_loss: 0.1483 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9583\n",
      "174\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1829 - accuracy: 0.9438 - precision: 0.9375 - recall: 0.4688 - AUC: 0.9163 - val_loss: 0.2094 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9271\n",
      "175\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1782 - accuracy: 0.9406 - precision: 0.9333 - recall: 0.4375 - AUC: 0.9313 - val_loss: 0.2681 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8542\n",
      "176\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1964 - accuracy: 0.9187 - precision: 0.6500 - recall: 0.4062 - AUC: 0.9130 - val_loss: 0.2020 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9201\n",
      "177\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1857 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9156 - val_loss: 0.1188 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9688\n",
      "178\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1642 - accuracy: 0.9344 - precision: 0.7391 - recall: 0.5312 - AUC: 0.9434 - val_loss: 0.1964 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9132\n",
      "179\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1652 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9327 - val_loss: 0.1274 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9774\n",
      "180\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1738 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9335 - val_loss: 0.2692 - val_accuracy: 0.8875 - val_precision: 0.4286 - val_recall: 0.3750 - val_AUC: 0.8655\n",
      "181\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1532 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9512 - val_loss: 0.1819 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9349\n",
      "182\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1809 - accuracy: 0.9438 - precision: 0.7917 - recall: 0.5938 - AUC: 0.9199 - val_loss: 0.2273 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8976\n",
      "183\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1483 - accuracy: 0.9313 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9557 - val_loss: 0.2326 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8628\n",
      "184\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2040 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9007 - val_loss: 0.1508 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9583\n",
      "185\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1931 - accuracy: 0.9219 - precision: 0.6296 - recall: 0.5312 - AUC: 0.9225 - val_loss: 0.2772 - val_accuracy: 0.8625 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8672\n",
      "186\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2000 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.8959 - val_loss: 0.0874 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9939\n",
      "187\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1505 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9565 - val_loss: 0.2419 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8542\n",
      "188\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1617 - accuracy: 0.9344 - precision: 0.7037 - recall: 0.5938 - AUC: 0.9438 - val_loss: 0.1565 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9392\n",
      "189\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1719 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9294 - val_loss: 0.1905 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8898\n",
      "190\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1750 - accuracy: 0.9375 - precision: 0.7308 - recall: 0.5938 - AUC: 0.9148 - val_loss: 0.1989 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9062\n",
      "191\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2367 - accuracy: 0.9000 - precision: 0.5000 - recall: 0.3125 - AUC: 0.8863 - val_loss: 0.2212 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9028\n",
      "192\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1771 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9251 - val_loss: 0.1853 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9158\n",
      "193\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1771 - accuracy: 0.9344 - precision: 0.7200 - recall: 0.5625 - AUC: 0.9418 - val_loss: 0.1826 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9340\n",
      "194\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2124 - accuracy: 0.9062 - precision: 0.5556 - recall: 0.3125 - AUC: 0.9091 - val_loss: 0.0992 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9852\n",
      "195\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1759 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9292 - val_loss: 0.2402 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.9097\n",
      "196\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1864 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9300 - val_loss: 0.1547 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9592\n",
      "197\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1098 - accuracy: 0.9625 - precision: 0.9545 - recall: 0.6562 - AUC: 0.9808 - val_loss: 0.1733 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9349\n",
      "198\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1881 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9200 - val_loss: 0.3255 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.7144\n",
      "199\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2148 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.8883 - val_loss: 0.1685 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9549\n",
      "200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1748 - accuracy: 0.9312 - precision: 0.8571 - recall: 0.3750 - AUC: 0.9357 - val_loss: 0.1118 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9905\n",
      "201\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1548 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9435 - val_loss: 0.2389 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8785\n",
      "202\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1740 - accuracy: 0.9438 - precision: 1.0000 - recall: 0.4375 - AUC: 0.9244 - val_loss: 0.1408 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9592\n",
      "203\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1849 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9283 - val_loss: 0.1495 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9661\n",
      "204\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2521 - accuracy: 0.8750 - precision: 0.2500 - recall: 0.1250 - AUC: 0.8706 - val_loss: 0.1282 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9627\n",
      "205\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1563 - accuracy: 0.9281 - precision: 0.8462 - recall: 0.3438 - AUC: 0.9563 - val_loss: 0.1758 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9418\n",
      "206\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1729 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9323 - val_loss: 0.3381 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.7873\n",
      "207\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2057 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.8916 - val_loss: 0.2114 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9062\n",
      "208\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1623 - accuracy: 0.9281 - precision: 0.6800 - recall: 0.5312 - AUC: 0.9506 - val_loss: 0.2218 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8837\n",
      "209\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1735 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9422 - val_loss: 0.2179 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8828\n",
      "210\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1946 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9092 - val_loss: 0.2440 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8507\n",
      "211\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1773 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9298 - val_loss: 0.0914 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.8750 - val_AUC: 0.9931\n",
      "212\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1661 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9376 - val_loss: 0.2359 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8733\n",
      "213\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1575 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9321 - val_loss: 0.1570 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9410\n",
      "214\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2228 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.8833 - val_loss: 0.0729 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.8750 - val_AUC: 0.9983\n",
      "215\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1850 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9287 - val_loss: 0.2581 - val_accuracy: 0.8875 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.8863\n",
      "216\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2135 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9072 - val_loss: 0.1656 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9462\n",
      "217\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2106 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.8818 - val_loss: 0.1887 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9132\n",
      "218\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2130 - accuracy: 0.9125 - precision: 0.5909 - recall: 0.4062 - AUC: 0.8963 - val_loss: 0.2464 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8446\n",
      "219\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1822 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9194 - val_loss: 0.2476 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8776\n",
      "220\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1660 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9357 - val_loss: 0.1782 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9358\n",
      "221\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1814 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9271 - val_loss: 0.1624 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9401\n",
      "222\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1582 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9444 - val_loss: 0.1058 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9861\n",
      "223\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1400 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9666 - val_loss: 0.2311 - val_accuracy: 0.8875 - val_precision: 0.4286 - val_recall: 0.3750 - val_AUC: 0.8976\n",
      "224\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1993 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9012 - val_loss: 0.1956 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9089\n",
      "225\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1417 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9427 - val_loss: 0.1170 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9809\n",
      "226\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2367 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.8585 - val_loss: 0.2068 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9115\n",
      "227\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1539 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9429 - val_loss: 0.2377 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8576\n",
      "228\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2009 - accuracy: 0.9094 - precision: 0.6000 - recall: 0.2812 - AUC: 0.9055 - val_loss: 0.1244 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9870\n",
      "229\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2013 - accuracy: 0.9125 - precision: 0.6250 - recall: 0.3125 - AUC: 0.9085 - val_loss: 0.2084 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8898\n",
      "230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step - loss: 0.1990 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9071 - val_loss: 0.1271 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9792\n",
      "231\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 0.1755 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9147 - val_loss: 0.2392 - val_accuracy: 0.9125 - val_precision: 1.0000 - val_recall: 0.1250 - val_AUC: 0.8455\n",
      "232\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2064 - accuracy: 0.9094 - precision: 0.5882 - recall: 0.3125 - AUC: 0.8898 - val_loss: 0.2046 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8950\n",
      "233\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1977 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9064 - val_loss: 0.1090 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9844\n",
      "234\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1801 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9184 - val_loss: 0.1035 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9748\n",
      "235\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1740 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9376 - val_loss: 0.2930 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.8507\n",
      "236\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1655 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9369 - val_loss: 0.1662 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9462\n",
      "237\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1547 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.5312 - AUC: 0.9495 - val_loss: 0.1859 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9453\n",
      "238\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2165 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.8815 - val_loss: 0.2139 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8984\n",
      "239\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1704 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9376 - val_loss: 0.2459 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8481\n",
      "240\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1768 - accuracy: 0.9187 - precision: 0.8000 - recall: 0.2500 - AUC: 0.9321 - val_loss: 0.2477 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8724\n",
      "241\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1544 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9588 - val_loss: 0.1546 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9332\n",
      "242\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1799 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9173 - val_loss: 0.1371 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9757\n",
      "243\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1660 - accuracy: 0.9438 - precision: 1.0000 - recall: 0.4375 - AUC: 0.9292 - val_loss: 0.1267 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9774\n",
      "244\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1859 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9245 - val_loss: 0.1610 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9601\n",
      "245\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1615 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9507 - val_loss: 0.1741 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9245\n",
      "246\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2213 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.8812 - val_loss: 0.1344 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9731\n",
      "247\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2155 - accuracy: 0.9219 - precision: 0.8182 - recall: 0.2812 - AUC: 0.8834 - val_loss: 0.1329 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9774\n",
      "248\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1896 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9197 - val_loss: 0.1478 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9592\n",
      "249\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1680 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9358 - val_loss: 0.1888 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8811\n",
      "250\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1775 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9314 - val_loss: 0.1054 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9913\n",
      "251\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1635 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9463 - val_loss: 0.1453 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9583\n",
      "252\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1836 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.9334 - val_loss: 0.1690 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9314\n",
      "253\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2097 - accuracy: 0.9156 - precision: 0.6667 - recall: 0.3125 - AUC: 0.8904 - val_loss: 0.2557 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8403\n",
      "254\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2137 - accuracy: 0.9094 - precision: 0.5714 - recall: 0.3750 - AUC: 0.8889 - val_loss: 0.1830 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9314\n",
      "255\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1829 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9236 - val_loss: 0.1165 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9679\n",
      "256\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2066 - accuracy: 0.9156 - precision: 0.6087 - recall: 0.4375 - AUC: 0.9002 - val_loss: 0.1407 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9653\n",
      "257\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1637 - accuracy: 0.9344 - precision: 0.7200 - recall: 0.5625 - AUC: 0.9445 - val_loss: 0.1987 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8967\n",
      "258\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1841 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.9289 - val_loss: 0.1253 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9844\n",
      "259\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2309 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.8696 - val_loss: 0.1994 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9019\n",
      "260\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1960 - accuracy: 0.9156 - precision: 0.6667 - recall: 0.3125 - AUC: 0.9198 - val_loss: 0.1954 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9141\n",
      "261\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2131 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.8849 - val_loss: 0.2890 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.7856\n",
      "262\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.1342 - accuracy: 0.9500 - precision: 0.9000 - recall: 0.5625 - AUC: 0.9701 - val_loss: 0.1778 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9444\n",
      "263\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1803 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9121 - val_loss: 0.2663 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8715\n",
      "264\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1928 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9138 - val_loss: 0.2215 - val_accuracy: 0.8875 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.9045\n",
      "265\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1772 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9336 - val_loss: 0.2092 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.8646\n",
      "266\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1627 - accuracy: 0.9437 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9393 - val_loss: 0.1430 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9410\n",
      "267\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1532 - accuracy: 0.9531 - precision: 0.9474 - recall: 0.5625 - AUC: 0.9398 - val_loss: 0.2332 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8863\n",
      "268\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1592 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9527 - val_loss: 0.1178 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9731\n",
      "269\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1882 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9164 - val_loss: 0.1877 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9071\n",
      "270\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1839 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9220 - val_loss: 0.1615 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9453\n",
      "271\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1782 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9342 - val_loss: 0.3152 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_AUC: 0.7726\n",
      "272\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1978 - accuracy: 0.9250 - precision: 0.8333 - recall: 0.3125 - AUC: 0.9058 - val_loss: 0.2297 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8620\n",
      "273\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1210 - accuracy: 0.9625 - precision: 0.9545 - recall: 0.6562 - AUC: 0.9681 - val_loss: 0.2212 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8724\n",
      "274\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2196 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.8974 - val_loss: 0.1343 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9722\n",
      "275\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1421 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9626 - val_loss: 0.2091 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9028\n",
      "276\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1252 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9720 - val_loss: 0.1553 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9566\n",
      "277\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1775 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9167 - val_loss: 0.1725 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.8793\n",
      "278\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1759 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9368 - val_loss: 0.1661 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9505\n",
      "279\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1857 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9180 - val_loss: 0.2092 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8950\n",
      "280\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1786 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9317 - val_loss: 0.1916 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8854\n",
      "281\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1564 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9511 - val_loss: 0.2045 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8872\n",
      "282\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2006 - accuracy: 0.9125 - precision: 0.5909 - recall: 0.4062 - AUC: 0.9140 - val_loss: 0.1466 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9679\n",
      "283\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2285 - accuracy: 0.9125 - precision: 0.6429 - recall: 0.2812 - AUC: 0.8729 - val_loss: 0.2921 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.7387\n",
      "284\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2008 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.9083 - val_loss: 0.1544 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9549\n",
      "285\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2078 - accuracy: 0.9219 - precision: 0.7692 - recall: 0.3125 - AUC: 0.8914 - val_loss: 0.1125 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9688\n",
      "286\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2065 - accuracy: 0.9094 - precision: 0.5882 - recall: 0.3125 - AUC: 0.9028 - val_loss: 0.1483 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9714\n",
      "287\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1470 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9530 - val_loss: 0.2520 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.7925\n",
      "288\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1916 - accuracy: 0.9406 - precision: 0.8824 - recall: 0.4688 - AUC: 0.9013 - val_loss: 0.2525 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8377\n",
      "289\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2397 - accuracy: 0.9219 - precision: 0.7692 - recall: 0.3125 - AUC: 0.8574 - val_loss: 0.3122 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.7292\n",
      "290\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1963 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9115 - val_loss: 0.2295 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8446\n",
      "291\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.889 - 0s 71ms/step - loss: 0.2225 - accuracy: 0.9094 - precision: 0.5789 - recall: 0.3438 - AUC: 0.8892 - val_loss: 0.1714 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9219\n",
      "292\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1657 - accuracy: 0.9438 - precision: 0.9375 - recall: 0.4688 - AUC: 0.9372 - val_loss: 0.1748 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9019\n",
      "293\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1740 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9296 - val_loss: 0.2078 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9245\n",
      "294\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1733 - accuracy: 0.9250 - precision: 0.7222 - recall: 0.4062 - AUC: 0.9438 - val_loss: 0.2038 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9149\n",
      "295\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1645 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9243 - val_loss: 0.1589 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1461 - accuracy: 0.9437 - precision: 0.7917 - recall: 0.5938 - AUC: 0.9608 - val_loss: 0.2722 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.7726\n",
      "297\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1960 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9189 - val_loss: 0.2471 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8281\n",
      "298\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1651 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9248 - val_loss: 0.0988 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9861\n",
      "299\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1723 - accuracy: 0.9500 - precision: 0.9444 - recall: 0.5312 - AUC: 0.9222 - val_loss: 0.1094 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9835\n",
      "300\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1714 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.9353 - val_loss: 0.2029 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9089\n",
      "301\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1517 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9563 - val_loss: 0.1140 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9896\n",
      "302\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1754 - accuracy: 0.9438 - precision: 0.8500 - recall: 0.5312 - AUC: 0.9181 - val_loss: 0.3416 - val_accuracy: 0.8625 - val_precision: 0.2000 - val_recall: 0.1250 - val_AUC: 0.7717\n",
      "303\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2091 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.8930 - val_loss: 0.2421 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8498\n",
      "304\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2183 - accuracy: 0.9125 - precision: 0.6250 - recall: 0.3125 - AUC: 0.8879 - val_loss: 0.2012 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9089\n",
      "305\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1760 - accuracy: 0.9375 - precision: 0.9286 - recall: 0.4062 - AUC: 0.9224 - val_loss: 0.2070 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9392\n",
      "306\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2046 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9085 - val_loss: 0.2341 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8793\n",
      "307\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2020 - accuracy: 0.9125 - precision: 0.5909 - recall: 0.4062 - AUC: 0.9060 - val_loss: 0.1330 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9696\n",
      "308\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1447 - accuracy: 0.9531 - precision: 0.8400 - recall: 0.6562 - AUC: 0.9409 - val_loss: 0.2268 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8767\n",
      "309\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.1780 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9213 - val_loss: 0.1534 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9497\n",
      "310\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.1891 - accuracy: 0.9281 - precision: 0.8462 - recall: 0.3438 - AUC: 0.9063 - val_loss: 0.1733 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9505\n",
      "311\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2089 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.8977 - val_loss: 0.2235 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8802\n",
      "312\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1665 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9321 - val_loss: 0.1242 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9740\n",
      "313\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1579 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9520 - val_loss: 0.1896 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9340\n",
      "314\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2098 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.9013 - val_loss: 0.1795 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9384\n",
      "315\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1413 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9604 - val_loss: 0.1574 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9523\n",
      "316\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2108 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.8915 - val_loss: 0.0630 - val_accuracy: 0.9750 - val_precision: 0.8750 - val_recall: 0.8750 - val_AUC: 0.9948\n",
      "317\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1891 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9313 - val_loss: 0.1635 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9488\n",
      "318\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1675 - accuracy: 0.9344 - precision: 0.7391 - recall: 0.5312 - AUC: 0.9387 - val_loss: 0.1191 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9826\n",
      "319\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1714 - accuracy: 0.9438 - precision: 0.8889 - recall: 0.5000 - AUC: 0.9243 - val_loss: 0.1570 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9635\n",
      "320\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1573 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9444 - val_loss: 0.1308 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9688\n",
      "321\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1428 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9588 - val_loss: 0.1364 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9740\n",
      "322\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1924 - accuracy: 0.9344 - precision: 0.7200 - recall: 0.5625 - AUC: 0.8955 - val_loss: 0.3133 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8108\n",
      "323\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1981 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9200 - val_loss: 0.3214 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.7483\n",
      "324\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1689 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9325 - val_loss: 0.2299 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8342\n",
      "325\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1992 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9202 - val_loss: 0.1558 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9479\n",
      "326\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2174 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.8926 - val_loss: 0.1917 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9201\n",
      "327\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2388 - accuracy: 0.9031 - precision: 0.5238 - recall: 0.3438 - AUC: 0.8855 - val_loss: 0.3078 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8038\n",
      "328\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2026 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.9068 - val_loss: 0.1313 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9531\n",
      "329\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1750 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9213 - val_loss: 0.1499 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9705\n",
      "330\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1977 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9061 - val_loss: 0.2548 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8142\n",
      "331\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1640 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9412 - val_loss: 0.2614 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8299\n",
      "332\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1889 - accuracy: 0.9250 - precision: 0.6667 - recall: 0.5000 - AUC: 0.9222 - val_loss: 0.2076 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9062\n",
      "333\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1964 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9025 - val_loss: 0.2758 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.8351\n",
      "334\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1904 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9236 - val_loss: 0.1156 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9844\n",
      "335\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2068 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.8902 - val_loss: 0.2010 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9158\n",
      "336\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1460 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9671 - val_loss: 0.1367 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9835\n",
      "337\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2429 - accuracy: 0.9281 - precision: 0.8462 - recall: 0.3438 - AUC: 0.8465 - val_loss: 0.1458 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9653\n",
      "338\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1989 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9049 - val_loss: 0.1063 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9731\n",
      "339\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1884 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9212 - val_loss: 0.2035 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9019\n",
      "340\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2363 - accuracy: 0.9031 - precision: 0.5455 - recall: 0.1875 - AUC: 0.8625 - val_loss: 0.1658 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9505\n",
      "341\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2367 - accuracy: 0.9125 - precision: 0.6429 - recall: 0.2812 - AUC: 0.8644 - val_loss: 0.3202 - val_accuracy: 0.8750 - val_precision: 0.3750 - val_recall: 0.3750 - val_AUC: 0.7865\n",
      "342\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1376 - accuracy: 0.9531 - precision: 0.8148 - recall: 0.6875 - AUC: 0.9596 - val_loss: 0.2622 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8698\n",
      "343\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1918 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9092 - val_loss: 0.2937 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.7856\n",
      "344\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1517 - accuracy: 0.9500 - precision: 0.9000 - recall: 0.5625 - AUC: 0.9474 - val_loss: 0.1929 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9470\n",
      "345\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1718 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9524 - val_loss: 0.2642 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8481\n",
      "346\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1768 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9289 - val_loss: 0.3014 - val_accuracy: 0.8875 - val_precision: 0.4286 - val_recall: 0.3750 - val_AUC: 0.8863\n",
      "347\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.1863 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9175 - val_loss: 0.2098 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9054\n",
      "348\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1954 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.8893 - val_loss: 0.2280 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8420\n",
      "349\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.1768 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9361 - val_loss: 0.2001 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9115\n",
      "350\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2361 - accuracy: 0.8906 - precision: 0.4118 - recall: 0.2188 - AUC: 0.8748 - val_loss: 0.2474 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8438\n",
      "351\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2273 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.8550 - val_loss: 0.1263 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9818\n",
      "352\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2383 - accuracy: 0.9125 - precision: 0.6111 - recall: 0.3438 - AUC: 0.8704 - val_loss: 0.1609 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9592\n",
      "353\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2107 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.8870 - val_loss: 0.2066 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9028\n",
      "354\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2155 - accuracy: 0.9094 - precision: 0.6154 - recall: 0.2500 - AUC: 0.8846 - val_loss: 0.1591 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9601\n",
      "355\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2212 - accuracy: 0.9062 - precision: 0.5455 - recall: 0.3750 - AUC: 0.8969 - val_loss: 0.1997 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8733\n",
      "356\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1978 - accuracy: 0.8969 - precision: 0.4737 - recall: 0.2812 - AUC: 0.9227 - val_loss: 0.1420 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9583\n",
      "357\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1854 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9159 - val_loss: 0.2487 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8455\n",
      "358\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.1927 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.8978 - val_loss: 0.2378 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8620\n",
      "359\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1705 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9369 - val_loss: 0.2158 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9080\n",
      "360\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1589 - accuracy: 0.9406 - precision: 0.7826 - recall: 0.5625 - AUC: 0.9580 - val_loss: 0.2661 - val_accuracy: 0.9125 - val_precision: 1.0000 - val_recall: 0.1250 - val_AUC: 0.7873\n",
      "361\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2274 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.8885 - val_loss: 0.1716 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9601\n",
      "362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2012 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.9003 - val_loss: 0.2209 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8568\n",
      "363\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.1351 - accuracy: 0.9469 - precision: 0.8000 - recall: 0.6250 - AUC: 0.9633 - val_loss: 0.1299 - val_accuracy: 0.9625 - val_precision: 0.8571 - val_recall: 0.7500 - val_AUC: 0.9592\n",
      "364\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.1521 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9495 - val_loss: 0.2022 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9062\n",
      "365\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2061 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.8918 - val_loss: 0.1978 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9132\n",
      "366\n",
      "1/1 [==============================] - 0s 158ms/step - loss: 0.2047 - accuracy: 0.9312 - precision: 0.8571 - recall: 0.3750 - AUC: 0.8918 - val_loss: 0.1702 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9540\n",
      "367\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2056 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8966 - val_loss: 0.2045 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9071\n",
      "368\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2179 - accuracy: 0.9031 - precision: 0.5556 - recall: 0.1562 - AUC: 0.9013 - val_loss: 0.2004 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9089\n",
      "369\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.1672 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9400 - val_loss: 0.1431 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9696\n",
      "370\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.1630 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9456 - val_loss: 0.2749 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.7995\n",
      "371\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1920 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9151 - val_loss: 0.2138 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8681\n",
      "372\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2080 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.8965 - val_loss: 0.1790 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9505\n",
      "373\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1827 - accuracy: 0.9156 - precision: 0.6316 - recall: 0.3750 - AUC: 0.9278 - val_loss: 0.1527 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9462\n",
      "374\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.1373 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9618 - val_loss: 0.1359 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9687\n",
      "375\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.1572 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9565 - val_loss: 0.1758 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9427\n",
      "376\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1904 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.9191 - val_loss: 0.1195 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9705\n",
      "377\n",
      "1/1 [==============================] - 0s 336ms/step - loss: 0.1968 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9070 - val_loss: 0.1178 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9679\n",
      "378\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.1752 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9229 - val_loss: 0.2182 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9227\n",
      "379\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.1856 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9275 - val_loss: 0.1634 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9436\n",
      "380\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.1810 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9300 - val_loss: 0.2249 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.8594\n",
      "381\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1926 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9382 - val_loss: 0.2371 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8698\n",
      "382\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1765 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9281 - val_loss: 0.1438 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9618\n",
      "383\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1954 - accuracy: 0.9094 - precision: 0.5714 - recall: 0.3750 - AUC: 0.9166 - val_loss: 0.1889 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9253\n",
      "384\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1751 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9295 - val_loss: 0.1663 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9349\n",
      "385\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1248 - accuracy: 0.9531 - precision: 0.8400 - recall: 0.6562 - AUC: 0.9709 - val_loss: 0.2223 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.8698\n",
      "386\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1807 - accuracy: 0.9312 - precision: 0.6786 - recall: 0.5938 - AUC: 0.9264 - val_loss: 0.1492 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9366\n",
      "387\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1878 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9215 - val_loss: 0.2116 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8715\n",
      "388\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1325 - accuracy: 0.9594 - precision: 0.9130 - recall: 0.6562 - AUC: 0.9635 - val_loss: 0.1652 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9306\n",
      "389\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1721 - accuracy: 0.9438 - precision: 0.8889 - recall: 0.5000 - AUC: 0.9343 - val_loss: 0.1902 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9132\n",
      "390\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1920 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9190 - val_loss: 0.1618 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9375\n",
      "391\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1738 - accuracy: 0.9281 - precision: 0.6800 - recall: 0.5312 - AUC: 0.9280 - val_loss: 0.1152 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9844\n",
      "392\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1935 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9034 - val_loss: 0.1298 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9661\n",
      "393\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1993 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9136 - val_loss: 0.1292 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9688\n",
      "394\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1662 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9425 - val_loss: 0.4019 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.7144\n",
      "395\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2059 - accuracy: 0.9125 - precision: 0.6250 - recall: 0.3125 - AUC: 0.9014 - val_loss: 0.1316 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9470\n",
      "396\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1436 - accuracy: 0.9500 - precision: 0.8333 - recall: 0.6250 - AUC: 0.9609 - val_loss: 0.2409 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8611\n",
      "397\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1706 - accuracy: 0.9406 - precision: 0.7407 - recall: 0.6250 - AUC: 0.9252 - val_loss: 0.2784 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.7830\n",
      "398\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2060 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.8932 - val_loss: 0.1546 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9384\n",
      "399\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1965 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9079 - val_loss: 0.2118 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8984\n",
      "400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1972 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9082 - val_loss: 0.1849 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8950\n",
      "401\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1875 - accuracy: 0.9375 - precision: 0.9286 - recall: 0.4062 - AUC: 0.9058 - val_loss: 0.2036 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8993\n",
      "402\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1383 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9623 - val_loss: 0.1848 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9253\n",
      "403\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1744 - accuracy: 0.9375 - precision: 0.9286 - recall: 0.4062 - AUC: 0.9259 - val_loss: 0.1145 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9861\n",
      "404\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1649 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9479 - val_loss: 0.1778 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9115\n",
      "405\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1795 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9202 - val_loss: 0.1347 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9722\n",
      "406\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1298 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9692 - val_loss: 0.2352 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8602\n",
      "407\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1623 - accuracy: 0.9313 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9437 - val_loss: 0.1916 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9115\n",
      "408\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2472 - accuracy: 0.9094 - precision: 0.6000 - recall: 0.2812 - AUC: 0.8599 - val_loss: 0.1613 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9132\n",
      "409\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1560 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9450 - val_loss: 0.1452 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9618\n",
      "410\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1474 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9601 - val_loss: 0.1580 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9627\n",
      "411\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1453 - accuracy: 0.9344 - precision: 0.7391 - recall: 0.5312 - AUC: 0.9590 - val_loss: 0.2061 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9262\n",
      "412\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1506 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9558 - val_loss: 0.2552 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8056\n",
      "413\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1698 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9391 - val_loss: 0.2503 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8186\n",
      "414\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1729 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9299 - val_loss: 0.2306 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8950\n",
      "415\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1584 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9283 - val_loss: 0.2902 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.8524\n",
      "416\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2100 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9001 - val_loss: 0.1399 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9505\n",
      "417\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1519 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9460 - val_loss: 0.3161 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8073\n",
      "418\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2198 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.8825 - val_loss: 0.1500 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9245\n",
      "419\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1884 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9062 - val_loss: 0.3893 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.7717\n",
      "420\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1730 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9277 - val_loss: 0.1201 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9844\n",
      "421\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1857 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.9238 - val_loss: 0.2884 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8151\n",
      "422\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1513 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9492 - val_loss: 0.2157 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8906\n",
      "423\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2235 - accuracy: 0.9187 - precision: 0.6500 - recall: 0.4062 - AUC: 0.8829 - val_loss: 0.3301 - val_accuracy: 0.8750 - val_precision: 0.3333 - val_recall: 0.2500 - val_AUC: 0.8281\n",
      "424\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2283 - accuracy: 0.9031 - precision: 0.5238 - recall: 0.3438 - AUC: 0.8966 - val_loss: 0.1565 - val_accuracy: 0.9125 - val_precision: 0.5714 - val_recall: 0.5000 - val_AUC: 0.9583\n",
      "425\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1813 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9265 - val_loss: 0.2153 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9175\n",
      "426\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1909 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9177 - val_loss: 0.1883 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9358\n",
      "427\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1594 - accuracy: 0.9469 - precision: 0.8000 - recall: 0.6250 - AUC: 0.9465 - val_loss: 0.1448 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9601\n",
      "428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1911 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9168 - val_loss: 0.1188 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9852\n",
      "429\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1833 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9348 - val_loss: 0.1847 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9227\n",
      "430\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1659 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9530 - val_loss: 0.1787 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9123\n",
      "431\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1706 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9293 - val_loss: 0.2059 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9193\n",
      "432\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2059 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.8985 - val_loss: 0.2416 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8090\n",
      "433\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2087 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.8875 - val_loss: 0.2355 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8802\n",
      "434\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1705 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9383 - val_loss: 0.1134 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9896\n",
      "435\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1730 - accuracy: 0.9250 - precision: 0.7000 - recall: 0.4375 - AUC: 0.9385 - val_loss: 0.1670 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9444\n",
      "436\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2562 - accuracy: 0.9031 - precision: 0.5333 - recall: 0.2500 - AUC: 0.8638 - val_loss: 0.2169 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8976\n",
      "437\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1841 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9190 - val_loss: 0.1912 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9418\n",
      "438\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1440 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9586 - val_loss: 0.2031 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8767\n",
      "439\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1646 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9488 - val_loss: 0.1486 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9687\n",
      "440\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1619 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9429 - val_loss: 0.2505 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8446\n",
      "441\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1985 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9080 - val_loss: 0.2018 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8915\n",
      "442\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1790 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9221 - val_loss: 0.2090 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8785\n",
      "443\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2199 - accuracy: 0.9062 - precision: 0.5714 - recall: 0.2500 - AUC: 0.8945 - val_loss: 0.1807 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9366\n",
      "444\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1987 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.8927 - val_loss: 0.1554 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9575\n",
      "445\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1488 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9531 - val_loss: 0.1888 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9201\n",
      "446\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1275 - accuracy: 0.9438 - precision: 0.9375 - recall: 0.4688 - AUC: 0.9740 - val_loss: 0.1413 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9661\n",
      "447\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1788 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9194 - val_loss: 0.1942 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9019\n",
      "448\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1500 - accuracy: 0.9406 - precision: 0.8824 - recall: 0.4688 - AUC: 0.9527 - val_loss: 0.2608 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8377\n",
      "449\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1635 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9397 - val_loss: 0.1604 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9575\n",
      "450\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2188 - accuracy: 0.9125 - precision: 0.6000 - recall: 0.3750 - AUC: 0.8914 - val_loss: 0.1031 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9878\n",
      "451\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2314 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.8543 - val_loss: 0.1328 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9635\n",
      "452\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1750 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9237 - val_loss: 0.1606 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9557\n",
      "453\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2247 - accuracy: 0.9125 - precision: 0.6111 - recall: 0.3438 - AUC: 0.8690 - val_loss: 0.2134 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8906\n",
      "454\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1455 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9546 - val_loss: 0.2031 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.8872\n",
      "455\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1820 - accuracy: 0.9187 - precision: 0.6500 - recall: 0.4062 - AUC: 0.9202 - val_loss: 0.1932 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.9227\n",
      "456\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1665 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9426 - val_loss: 0.1561 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9488\n",
      "457\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.2030 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9183 - val_loss: 0.1940 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9193\n",
      "458\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1737 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9306 - val_loss: 0.1898 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9340\n",
      "459\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1818 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9141 - val_loss: 0.1368 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9740\n",
      "460\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1497 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9634 - val_loss: 0.2151 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8733\n",
      "461\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1677 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9419 - val_loss: 0.1573 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9427\n",
      "462\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2047 - accuracy: 0.9062 - precision: 0.5500 - recall: 0.3438 - AUC: 0.9051 - val_loss: 0.1852 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9427\n",
      "463\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2192 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8779 - val_loss: 0.2042 - val_accuracy: 0.9250 - val_precision: 0.6250 - val_recall: 0.6250 - val_AUC: 0.8733\n",
      "464\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2217 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.8815 - val_loss: 0.2702 - val_accuracy: 0.8625 - val_precision: 0.2857 - val_recall: 0.2500 - val_AUC: 0.8307\n",
      "465\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1755 - accuracy: 0.9375 - precision: 0.8000 - recall: 0.5000 - AUC: 0.9252 - val_loss: 0.1417 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9731\n",
      "466\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1471 - accuracy: 0.9500 - precision: 0.8333 - recall: 0.6250 - AUC: 0.9473 - val_loss: 0.1187 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9809\n",
      "467\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1515 - accuracy: 0.9562 - precision: 0.9091 - recall: 0.6250 - AUC: 0.9431 - val_loss: 0.2874 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.7622\n",
      "468\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1826 - accuracy: 0.9312 - precision: 0.8125 - recall: 0.4062 - AUC: 0.9186 - val_loss: 0.2364 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8073\n",
      "469\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1929 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.9111 - val_loss: 0.1325 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9731\n",
      "470\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2109 - accuracy: 0.9062 - precision: 0.5714 - recall: 0.2500 - AUC: 0.9085 - val_loss: 0.2553 - val_accuracy: 0.8750 - val_precision: 0.2500 - val_recall: 0.1250 - val_AUC: 0.8707\n",
      "471\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2218 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.8816 - val_loss: 0.1812 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8854\n",
      "472\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1506 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9529 - val_loss: 0.1476 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9653\n",
      "473\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1784 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9337 - val_loss: 0.0819 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9931\n",
      "474\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2083 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.8857 - val_loss: 0.2104 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9253\n",
      "475\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1981 - accuracy: 0.9187 - precision: 0.6250 - recall: 0.4688 - AUC: 0.9074 - val_loss: 0.0449 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.8750 - val_AUC: 1.0000\n",
      "476\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1796 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9224 - val_loss: 0.1713 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9210\n",
      "477\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1698 - accuracy: 0.9375 - precision: 0.8333 - recall: 0.4688 - AUC: 0.9266 - val_loss: 0.1391 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9740\n",
      "478\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1724 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9339 - val_loss: 0.1803 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9323\n",
      "479\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1990 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9015 - val_loss: 0.1765 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9262\n",
      "480\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1659 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9385 - val_loss: 0.2909 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.7847\n",
      "481\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1946 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.8965 - val_loss: 0.1860 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9271\n",
      "482\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1332 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9629 - val_loss: 0.1209 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9844\n",
      "483\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1588 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9444 - val_loss: 0.1261 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9661\n",
      "484\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1637 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9491 - val_loss: 0.1892 - val_accuracy: 0.8875 - val_precision: 0.3333 - val_recall: 0.1250 - val_AUC: 0.9401\n",
      "485\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2288 - accuracy: 0.9062 - precision: 0.5833 - recall: 0.2188 - AUC: 0.8872 - val_loss: 0.2494 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8594\n",
      "486\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1958 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9130 - val_loss: 0.0497 - val_accuracy: 0.9875 - val_precision: 1.0000 - val_recall: 0.8750 - val_AUC: 1.0000\n",
      "487\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2005 - accuracy: 0.9219 - precision: 0.7333 - recall: 0.3438 - AUC: 0.9080 - val_loss: 0.2848 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8281\n",
      "488\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1761 - accuracy: 0.9344 - precision: 0.8235 - recall: 0.4375 - AUC: 0.9187 - val_loss: 0.1139 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9809\n",
      "489\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1681 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9428 - val_loss: 0.1623 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9410\n",
      "490\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1782 - accuracy: 0.9187 - precision: 0.7143 - recall: 0.3125 - AUC: 0.9384 - val_loss: 0.2635 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.1250 - val_AUC: 0.8099\n",
      "491\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1633 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9410 - val_loss: 0.1039 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9809\n",
      "492\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1185 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9756 - val_loss: 0.2732 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8438\n",
      "493\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1772 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9355 - val_loss: 0.1812 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9349\n",
      "494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1709 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9321 - val_loss: 0.1458 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9705\n",
      "495\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2731 - accuracy: 0.9062 - precision: 0.5500 - recall: 0.3438 - AUC: 0.8727 - val_loss: 0.1115 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9722\n",
      "496\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1756 - accuracy: 0.9219 - precision: 0.6522 - recall: 0.4688 - AUC: 0.9397 - val_loss: 0.2422 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9106\n",
      "497\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1644 - accuracy: 0.9344 - precision: 0.7895 - recall: 0.4688 - AUC: 0.9429 - val_loss: 0.0748 - val_accuracy: 0.9875 - val_precision: 0.8889 - val_recall: 1.0000 - val_AUC: 0.9913\n",
      "498\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1840 - accuracy: 0.9406 - precision: 0.9333 - recall: 0.4375 - AUC: 0.9075 - val_loss: 0.1581 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9514\n",
      "499\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1457 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9645 - val_loss: 0.1325 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9696\n",
      "500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2072 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9079 - val_loss: 0.2649 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8299\n",
      "501\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1958 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.8808 - val_loss: 0.2031 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9080\n",
      "502\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1518 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9529 - val_loss: 0.1438 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9644\n",
      "503\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1216 - accuracy: 0.9500 - precision: 0.8077 - recall: 0.6562 - AUC: 0.9714 - val_loss: 0.2188 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.8524\n",
      "504\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1521 - accuracy: 0.9500 - precision: 0.8636 - recall: 0.5938 - AUC: 0.9430 - val_loss: 0.1537 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9722\n",
      "505\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1938 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9107 - val_loss: 0.1624 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9444\n",
      "506\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2059 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.8915 - val_loss: 0.1709 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9427\n",
      "507\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1882 - accuracy: 0.9281 - precision: 0.7368 - recall: 0.4375 - AUC: 0.9203 - val_loss: 0.2253 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8759\n",
      "508\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1767 - accuracy: 0.9469 - precision: 0.8571 - recall: 0.5625 - AUC: 0.9252 - val_loss: 0.2687 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8281\n",
      "509\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1719 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9338 - val_loss: 0.1978 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9210\n",
      "510\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2046 - accuracy: 0.9094 - precision: 0.6000 - recall: 0.2812 - AUC: 0.9118 - val_loss: 0.1456 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9601\n",
      "511\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1391 - accuracy: 0.9406 - precision: 0.7600 - recall: 0.5938 - AUC: 0.9644 - val_loss: 0.1734 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9531\n",
      "512\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1941 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9119 - val_loss: 0.2529 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.3750 - val_AUC: 0.8403\n",
      "513\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2088 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.8921 - val_loss: 0.2310 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.8707\n",
      "514\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1755 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9376 - val_loss: 0.2027 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.9149\n",
      "515\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2119 - accuracy: 0.9187 - precision: 0.6250 - recall: 0.4688 - AUC: 0.8947 - val_loss: 0.1542 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9366\n",
      "516\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2122 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9042 - val_loss: 0.1401 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9410\n",
      "517\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1740 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9401 - val_loss: 0.2060 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.8941\n",
      "518\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1887 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9172 - val_loss: 0.2388 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8646\n",
      "519\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1979 - accuracy: 0.9156 - precision: 0.6000 - recall: 0.4688 - AUC: 0.9185 - val_loss: 0.2444 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.8620\n",
      "520\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1999 - accuracy: 0.9219 - precision: 0.6667 - recall: 0.4375 - AUC: 0.9043 - val_loss: 0.0929 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9965\n",
      "521\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.1804 - accuracy: 0.9469 - precision: 0.8947 - recall: 0.5312 - AUC: 0.9110 - val_loss: 0.1903 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9193\n",
      "522\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1522 - accuracy: 0.9469 - precision: 0.9412 - recall: 0.5000 - AUC: 0.9511 - val_loss: 0.1171 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9861\n",
      "523\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1733 - accuracy: 0.9312 - precision: 0.7083 - recall: 0.5312 - AUC: 0.9260 - val_loss: 0.0923 - val_accuracy: 0.9625 - val_precision: 1.0000 - val_recall: 0.6250 - val_AUC: 0.9913\n",
      "524\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1736 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9185 - val_loss: 0.2308 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8490\n",
      "525\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2009 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.8958 - val_loss: 0.2086 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8941\n",
      "526\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1536 - accuracy: 0.9406 - precision: 0.8421 - recall: 0.5000 - AUC: 0.9547 - val_loss: 0.1756 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9358\n",
      "527\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1713 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9355 - val_loss: 0.1844 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.9149\n",
      "528\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1702 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.9361 - val_loss: 0.2280 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8646\n",
      "529\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2055 - accuracy: 0.9187 - precision: 0.6875 - recall: 0.3438 - AUC: 0.9011 - val_loss: 0.1743 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9314\n",
      "530\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1908 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9204 - val_loss: 0.2018 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.8533\n",
      "531\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2021 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9013 - val_loss: 0.1767 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9306\n",
      "532\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1855 - accuracy: 0.9187 - precision: 0.6500 - recall: 0.4062 - AUC: 0.9169 - val_loss: 0.1640 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9627\n",
      "533\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2110 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.8976 - val_loss: 0.1258 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9913\n",
      "534\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1773 - accuracy: 0.9281 - precision: 0.8000 - recall: 0.3750 - AUC: 0.9301 - val_loss: 0.1091 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9878\n",
      "535\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1845 - accuracy: 0.9406 - precision: 0.8824 - recall: 0.4688 - AUC: 0.9210 - val_loss: 0.1586 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9462\n",
      "536\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2098 - accuracy: 0.9156 - precision: 0.6923 - recall: 0.2812 - AUC: 0.9004 - val_loss: 0.2500 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8767\n",
      "537\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1427 - accuracy: 0.9469 - precision: 0.8261 - recall: 0.5938 - AUC: 0.9501 - val_loss: 0.1589 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9470\n",
      "538\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1676 - accuracy: 0.9187 - precision: 0.6667 - recall: 0.3750 - AUC: 0.9360 - val_loss: 0.2906 - val_accuracy: 0.8875 - val_precision: 0.4000 - val_recall: 0.2500 - val_AUC: 0.7943\n",
      "539\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1491 - accuracy: 0.9375 - precision: 0.8750 - recall: 0.4375 - AUC: 0.9543 - val_loss: 0.1895 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9010\n",
      "540\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1538 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9515 - val_loss: 0.2289 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9297\n",
      "541\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1988 - accuracy: 0.9250 - precision: 0.7857 - recall: 0.3438 - AUC: 0.8938 - val_loss: 0.2053 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.8993\n",
      "542\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1432 - accuracy: 0.9531 - precision: 0.8400 - recall: 0.6562 - AUC: 0.9491 - val_loss: 0.1415 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9540\n",
      "543\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1581 - accuracy: 0.9531 - precision: 0.9474 - recall: 0.5625 - AUC: 0.9295 - val_loss: 0.1760 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.9271\n",
      "544\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1535 - accuracy: 0.9438 - precision: 0.8182 - recall: 0.5625 - AUC: 0.9485 - val_loss: 0.1198 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9861\n",
      "545\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.2012 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9009 - val_loss: 0.1893 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9201\n",
      "546\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2121 - accuracy: 0.9000 - precision: 0.5000 - recall: 0.2812 - AUC: 0.9120 - val_loss: 0.1952 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.8984\n",
      "547\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1962 - accuracy: 0.9156 - precision: 0.6087 - recall: 0.4375 - AUC: 0.9201 - val_loss: 0.1911 - val_accuracy: 0.9250 - val_precision: 1.0000 - val_recall: 0.2500 - val_AUC: 0.9236\n",
      "548\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1620 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9436 - val_loss: 0.1920 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9071\n",
      "549\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2118 - accuracy: 0.9156 - precision: 0.6471 - recall: 0.3438 - AUC: 0.8836 - val_loss: 0.1589 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9366\n",
      "550\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1925 - accuracy: 0.9344 - precision: 0.8667 - recall: 0.4062 - AUC: 0.9042 - val_loss: 0.1148 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9661\n",
      "551\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1407 - accuracy: 0.9375 - precision: 0.7308 - recall: 0.5938 - AUC: 0.9646 - val_loss: 0.1383 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9688\n",
      "552\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1772 - accuracy: 0.9344 - precision: 0.7619 - recall: 0.5000 - AUC: 0.9355 - val_loss: 0.2330 - val_accuracy: 0.9250 - val_precision: 0.7500 - val_recall: 0.3750 - val_AUC: 0.8281\n",
      "553\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1503 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9509 - val_loss: 0.1232 - val_accuracy: 0.9375 - val_precision: 0.7143 - val_recall: 0.6250 - val_AUC: 0.9696\n",
      "554\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1987 - accuracy: 0.9281 - precision: 0.6957 - recall: 0.5000 - AUC: 0.8950 - val_loss: 0.1357 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9714\n",
      "555\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1528 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9478 - val_loss: 0.1555 - val_accuracy: 0.9125 - val_precision: 0.6667 - val_recall: 0.2500 - val_AUC: 0.9557\n",
      "556\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1945 - accuracy: 0.9187 - precision: 0.6364 - recall: 0.4375 - AUC: 0.9125 - val_loss: 0.1892 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9488\n",
      "557\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1960 - accuracy: 0.9219 - precision: 0.7059 - recall: 0.3750 - AUC: 0.9049 - val_loss: 0.1117 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9722\n",
      "558\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1791 - accuracy: 0.9375 - precision: 0.7500 - recall: 0.5625 - AUC: 0.9127 - val_loss: 0.1178 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.9800\n",
      "559\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1529 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9534 - val_loss: 0.1148 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9861\n",
      "560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1745 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9376 - val_loss: 0.1141 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9913\n",
      "561\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1827 - accuracy: 0.9312 - precision: 0.7273 - recall: 0.5000 - AUC: 0.9281 - val_loss: 0.1440 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9653\n",
      "562\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1725 - accuracy: 0.9312 - precision: 0.7500 - recall: 0.4688 - AUC: 0.9255 - val_loss: 0.1751 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9210\n",
      "563\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1442 - accuracy: 0.9344 - precision: 0.7391 - recall: 0.5312 - AUC: 0.9630 - val_loss: 0.1285 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9757\n",
      "564\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1745 - accuracy: 0.9281 - precision: 0.7143 - recall: 0.4688 - AUC: 0.9215 - val_loss: 0.1395 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9505\n",
      "565\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2202 - accuracy: 0.9250 - precision: 0.7500 - recall: 0.3750 - AUC: 0.8784 - val_loss: 0.1735 - val_accuracy: 0.9375 - val_precision: 1.0000 - val_recall: 0.3750 - val_AUC: 0.9297\n",
      "566\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1777 - accuracy: 0.9312 - precision: 0.7778 - recall: 0.4375 - AUC: 0.9227 - val_loss: 0.1165 - val_accuracy: 0.9500 - val_precision: 0.7500 - val_recall: 0.7500 - val_AUC: 0.9818\n",
      "567\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2259 - accuracy: 0.9094 - precision: 0.5652 - recall: 0.4062 - AUC: 0.8953 - val_loss: 0.1830 - val_accuracy: 0.9000 - val_precision: 0.5000 - val_recall: 0.2500 - val_AUC: 0.9306\n",
      "568\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1759 - accuracy: 0.9281 - precision: 0.7647 - recall: 0.4062 - AUC: 0.9313 - val_loss: 0.1401 - val_accuracy: 0.9500 - val_precision: 0.8333 - val_recall: 0.6250 - val_AUC: 0.9609\n",
      "569\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1974 - accuracy: 0.9250 - precision: 0.6818 - recall: 0.4688 - AUC: 0.9099 - val_loss: 0.1488 - val_accuracy: 0.9375 - val_precision: 0.8000 - val_recall: 0.5000 - val_AUC: 0.9618\n",
      "570\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1758 - accuracy: 0.9406 - precision: 0.8095 - recall: 0.5312 - AUC: 0.9307 - val_loss: 0.1598 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9618\n",
      "571\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1518 - accuracy: 0.9375 - precision: 1.0000 - recall: 0.3750 - AUC: 0.9570 - val_loss: 0.2651 - val_accuracy: 0.9125 - val_precision: 0.6000 - val_recall: 0.3750 - val_AUC: 0.8498\n",
      "572\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1841 - accuracy: 0.9219 - precision: 0.6842 - recall: 0.4062 - AUC: 0.9248 - val_loss: 0.1220 - val_accuracy: 0.9750 - val_precision: 1.0000 - val_recall: 0.7500 - val_AUC: 0.9575\n",
      "573\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2001 - accuracy: 0.9094 - precision: 0.5882 - recall: 0.3125 - AUC: 0.9082 - val_loss: 0.1879 - val_accuracy: 0.9500 - val_precision: 1.0000 - val_recall: 0.5000 - val_AUC: 0.8889\n",
      "574\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1432 - accuracy: 0.9375 - precision: 0.7727 - recall: 0.5312 - AUC: 0.9625 - val_loss: 0.1295 - val_accuracy: 0.9250 - val_precision: 0.6667 - val_recall: 0.5000 - val_AUC: 0.9635\n",
      "575\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-21625db61b83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         model2.fit(x_batch, y_batch,\n\u001b[0;32m     26\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                    verbose=1)\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mbatches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\sub\\anaconda3\\envs\\sub_3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "epochs = 2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "\n",
    "for e in range(epochs) :\n",
    "    print('Epochs : ',e)\n",
    "    batches = 0\n",
    "    for (x_batch, y_batch), (val_x, val_y) in zip(_datagen.flow(x_train, y_train, batch_size=32, subset='training'),\n",
    "                               _datagen.flow(x_train, y_train, batch_size=8, subset='validation')) :\n",
    "        print(batches)\n",
    "        model2.fit(x_batch, y_batch,\n",
    "                   validation_data=(val_x, val_y),\n",
    "                   verbose=1)\n",
    "        batches += 1\n",
    "        \n",
    "        if batches >= len(x_train) / 32:\n",
    "            break\n",
    "\n",
    "\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# _datagen.fit(x_train)\n",
    "\n",
    "# # fits the model on batches with real-time data augmentation:\n",
    "# model2.fit(_datagen.flow(x_train, y_train, batch_size=32,\n",
    "#          subset='training'),\n",
    "#          validation_data=_datagen.flow(x_train, y_train,\n",
    "#          batch_size=8, subset='validation'),\n",
    "#          steps_per_epoch=len(x_train) / 32, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0dedd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
